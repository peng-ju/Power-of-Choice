Timer unit: 1e-06 s

Total time: 29.6359 s
File: trainer.py
Function: run at line 75

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    75                                           @profile
    76                                           def run(rank, args):
    77                                               # init logs directory
    78         1          0.0      0.0      0.0      save_path = "./logs/"
    79         1          1.0      1.0      0.0      fracC = args.clients_per_round/args.num_clients
    80         1          4.0      4.0      0.0      fold = f"lr{args.lr:.4f}_bs{args.bs}_cp{args.localE}_a{args.alpha:.2f}_e{args.seed}_r0_n{args.num_clients}_f{fracC:.2f}/"
    81         1          0.0      0.0      0.0      if args.commE:
    82                                                   fold = "com_"+fold
    83         1          1.0      1.0      0.0      folder_name = save_path + args.name + "/" + fold
    84         7          4.0      0.6      0.0      file_name = f"{args.algo}_rr{args.rnd_ratio:.2f}_dr{args.delete_ratio:.2f}_lr{args.lr:.3f}_bs{args.bs:d}_cp{args.localE:d}"\
    85         6          1.0      0.2      0.0                      f"_a{args.alpha:.2f}_e{args.seed}_r{rank}_n{args.num_clients}_f{fracC:.2f}_p{args.powd}.csv"
    86         1         42.0     42.0      0.0      pathlib.Path(folder_name).mkdir(parents=True, exist_ok=True)
    87                                           
    88                                               # initiate log file
    89         1          1.0      1.0      0.0      saveFileName = folder_name+file_name
    90         1          0.0      0.0      0.0      args.out_fname = saveFileName
    91         1         11.0     11.0      0.0      args_str = [f"{key},{value}" for (key, value) in vars(args).items()]
    92         2       1421.0    710.5      0.0      with open(args.out_fname, "w+") as f:
    93         3          6.0      2.0      0.0          print("BEGIN-TRAINING\n" + "\n".join(args_str) + \
    94         2          0.0      0.0      0.0              "\nEpoch,itr,loss,trainloss,avg:Loss,Prec@1,avg:Prec@1,val,trainval,updtime,comptime,seltime,entime", file=f)
    95                                           
    96                                               # seed for reproducibility
    97         1         13.0     13.0      0.0      random.seed(args.seed)
    98         1         19.0     19.0      0.0      np.random.seed(args.seed)
    99         1       1217.0   1217.0      0.0      torch.manual_seed(args.seed)
   100         1        110.0    110.0      0.0      torch.cuda.manual_seed(args.seed)
   101         1          5.0      5.0      0.0      torch.backends.cudnn.deterministic = True
   102                                           
   103                                               # load data
   104         1      75050.0  75050.0      0.3      partitioner, dataratios, train_loader, test_loader = utils.partition_dataset(args, rnd=0)
   105                                           
   106                                               # tracking client loss values, frequency for each client
   107         1          2.0      2.0      0.0      client_freq, client_loss_proxy = np.zeros(args.num_clients), np.zeros(args.num_clients)
   108                                           
   109                                               # define model
   110         1         14.0     14.0      0.0      input_dims = np.prod(args.img_size)
   111         1          0.0      0.0      0.0      if args.model == "MLP":
   112         1        553.0    553.0      0.0          model = models.MLP_FMNIST(dim_in=input_dims, dim_hidden1=64, dim_hidden2 = 30, dim_out=args.num_classes).to(device)
   113                                               elif args.model == "CNN":
   114                                                   model = models.CNN_CIFAR(args).to(device)
   115                                           
   116                                               # allocate buffer for global and aggregate parameters
   117                                               # ref: https://discuss.pytorch.org/t/how-to-assign-an-arbitrary-tensor-to-models-parameter/44082/3
   118         1          0.0      0.0      0.0      global_parameters = []
   119         1          0.0      0.0      0.0      aggregate_parameters = []
   120         2          5.0      2.5      0.0      with torch.no_grad():
   121         7         32.0      4.6      0.0          for param in model.parameters():
   122         6         47.0      7.8      0.0              global_parameters.append(param.detach().clone())
   123         6         64.0     10.7      0.0              aggregate_parameters.append(torch.zeros_like(param))            
   124                                           
   125                                               # define loss function
   126         1         34.0     34.0      0.0      criterion = nn.NLLLoss().to(device)
   127                                           
   128                                               # define optimizer
   129         2         59.0     29.5      0.0      optimizer = torch.optim.SGD(model.parameters(), 
   130         1          1.0      1.0      0.0                                  lr=args.lr, 
   131         1          0.0      0.0      0.0                                  momentum=args.momentum, 
   132         1          0.0      0.0      0.0                                  nesterov=False,
   133         1          0.0      0.0      0.0                                  weight_decay=1e-4)
   134                                               # optimizer = DistOptimizer(model.parameters(),
   135                                               #                             lr=args.lr,
   136                                               #                             gmf=args.gmf, # set to 0
   137                                               #                             mu = args.mu, # set to 0
   138                                               #                             ratio=dataratios[rank],
   139                                               #                             momentum=args.momentum, # set to 0
   140                                               #                             nesterov = False,
   141                                               #                             weight_decay=1e-4)
   142                                           
   143                                               # randomly select clients for the first round
   144         1          0.0      0.0      0.0      replace_param = False
   145         1          0.0      0.0      0.0      if args.algo =="rand":
   146         1          0.0      0.0      0.0          replace_param = True
   147         1         47.0     47.0      0.0      idxs_users = np.random.choice(args.num_clients, size=args.clients_per_round, replace=replace_param)
   148                                           
   149                                               # start communication rounds
   150         6          3.0      0.5      0.0      for rnd in range(args.rounds):
   151         5          6.0      1.2      0.0          round_start = time.time()
   152                                           
   153                                                   # (optional) decay learning rate according to round index
   154         5          3.0      0.6      0.0          if args.decay == True:
   155                                                       # update_learning_rate(optimizer, rnd, args.lr)
   156         5          0.0      0.0      0.0              if rnd == 149:
   157                                                           lr = args.lr/2
   158                                                           logging.info("Updating learning rate to {}".format(lr))
   159                                                           for param_group in optimizer.param_groups:
   160                                                               param_group["lr"] = lr
   161                                           
   162         5          0.0      0.0      0.0              if rnd == 299:
   163                                                           lr = args.lr/4
   164                                                           logging.info("Updating learning rate to {}".format(lr))
   165                                                           for param_group in optimizer.param_groups:
   166                                                               param_group["lr"] = lr
   167                                           
   168                                                   # zero aggregate parameters for accumulation of local parameters
   169        10         70.0      7.0      0.0          with torch.no_grad():
   170        35         27.0      0.8      0.0              for param in aggregate_parameters:
   171        30        346.0     11.5      0.0                  param.zero_()
   172                                           
   173                                                   # for each client `i`
   174        20         27.0      1.4      0.0          for i in idxs_users:
   175                                                       # send global parameters to client `i`
   176        30         79.0      2.6      0.0              with torch.no_grad():
   177       105        663.0      6.3      0.0                  for param, global_param in zip(model.parameters(), global_parameters):
   178        90        583.0      6.5      0.0                      param.copy_(global_param)
   179                                                       
   180                                                       # run E steps of SGD on client `i`
   181        15          2.0      0.1      0.0              loss_final = 0
   182        15          4.0      0.3      0.0              comm_update_start = time.time()
   183       465         94.0      0.2      0.0              for t in range(args.localE):
   184       450      43810.0     97.4      0.1                  singlebatch_loader = utils.partitiondata_loader(partitioner, i, args.bs)
   185       450    2215483.0   4923.3      7.5                  loss = train(i, model, criterion, optimizer, singlebatch_loader, t)  <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
   186       450        391.0      0.9      0.0                  loss_final += loss/args.localE
   187        15         20.0      1.3      0.0              comm_update_end = time.time()
   188        15          9.0      0.6      0.0              update_time = comm_update_end - comm_update_start
   189                                           
   190                                                       # send local parameters from client `i` to server for aggregation
   191        30        111.0      3.7      0.0              with torch.no_grad():
   192        15          4.0      0.3      0.0                  weight = 1/args.clients_per_round
   193       105        466.0      4.4      0.0                  for aggregate_param, param in zip(aggregate_parameters, model.parameters()):
   194        90        297.0      3.3      0.0                      aggregate_param.add_(param, alpha=weight)
   195                                                       
   196                                                       # update client frequency and loss values
   197        15         69.0      4.6      0.0              client_freq[i] += 1
   198        15         15.0      1.0      0.0              client_loss_proxy[i] = loss_final
   199                                           
   200                                                   # (??) getting value function for client selection (required only for "rpow-d", "afl")
   201         5        152.0     30.4      0.0          not_visited = np.where(client_freq == 0)[0]
   202       463         49.0      0.1      0.0          for j in not_visited:
   203       458         52.0      0.1      0.0              if args.algo == "afl":
   204                                                           client_loss_proxy[j] = -np.inf
   205                                                       else:
   206       458         88.0      0.2      0.0                  client_loss_proxy[j] = np.inf
   207                                           
   208                                                   # update global parameters
   209        10         20.0      2.0      0.0          with torch.no_grad():
   210        35          7.0      0.2      0.0              for global_param, aggregate_param in zip(global_parameters, aggregate_parameters):
   211        30        150.0      5.0      0.0                  global_param.copy_(aggregate_param)
   212                                           
   213                                                   # set model with global parameters
   214        10         16.0      1.6      0.0          with torch.no_grad():
   215        35        126.0      3.6      0.0              for param, global_param in zip(model.parameters(), global_parameters):
   216        30         73.0      2.4      0.0                  param.copy_(global_param)
   217                                           
   218                                                   # evaluate test accuracy
   219         5    7989212.0    2e+06     27.0          test_acc, test_loss = evaluate(model, test_loader, criterion)  <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
   220                                           
   221                                                   # evaluate loss values and sync selected frequency
   222         5   19299982.0    4e+06     65.1          client_loss, client_comptime = evaluate_clients(model, criterion, partitioner)  <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
   223         5        250.0     50.0      0.0          train_loss = sum([client_loss[i]*dataratios[i] for i in range(args.num_clients)])
   224         5          6.0      1.2      0.0          train_loss1 = sum(client_loss)/args.num_clients
   225                                           
   226                                                   # select clients for the next round
   227         5          0.0      0.0      0.0          sel_time, comp_time = 0, 0
   228         5          2.0      0.4      0.0          sel_time_start = time.time()
   229         5       1212.0    242.4      0.0          idxs_users, rnd_idx = utils.select_clients(dataratios, client_loss, client_loss_proxy, args, rnd)
   230                                                   # print(f"len rnd_idx {len(rnd_idx)} idxs_users {len(idxs_users)}")
   231         5          2.0      0.4      0.0          sel_time_end = time.time()
   232         5          1.0      0.2      0.0          sel_time = sel_time_end - sel_time_start
   233                                           
   234         5          5.0      1.0      0.0          if args.algo == "pow-d" or args.algo == "pow-dint":
   235                                                       comp_time = max([client_comptime[int(i)] for i in rnd_idx])
   236                                           
   237                                                   # record metrics
   238         5          1.0      0.2      0.0          round_end = time.time()
   239         5         25.0      5.0      0.0          round_duration = round(round_end - round_start, 1)
   240         5        757.0    151.4      0.0          logging.info(f"[{round_duration} s] Round {rnd} rank {rank} test accuracy {test_acc:.3f} test loss {test_loss:.3f}")
   241        10       2238.0    223.8      0.0          with open(args.out_fname, "+a") as f:
   242        30        109.0      3.6      0.0              print(f"{rnd},{-1},{test_loss:.4f},{train_loss:.4f},-1,-1,-1,{test_acc:.4f},{train_loss1:.4f},"
   243        25          3.0      0.1      0.0                    f"{update_time:.4f},{comp_time:.4f},{sel_time:.4f},{update_time+comp_time+sel_time:.4f}", file=f)
   244         1          0.0      0.0      0.0      return

Total time: 19.296 s
File: trainer.py
Function: evaluate_clients at line 246

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   246                                           @profile
   247                                           def evaluate_clients(model, criterion, partition):
   248                                               """
   249                                               Evaluate each client on their local train dataset against the current global model
   250                                           
   251                                               Evaluating each client"s local loss values for the current global model for client selection
   252                                               :param model: current global model
   253                                               :param criterion: loss function
   254                                               :param partition: dataset dict for clients
   255                                               :return: cli_loss = list of local loss values, cli_comptime = list of computation time
   256                                               """
   257                                           
   258         5          2.0      0.4      0.0      client_comptime, client_loss = [], []
   259         5        284.0     56.8      0.0      model.eval()
   260                                           
   261                                               # Get data from client to evaluate local loss on
   262       505        101.0      0.2      0.0      for i in range(args.num_clients):
   263       500       1642.0      3.3      0.0          partitioned = partition.use(i)
   264                                           
   265                                                   # cpow-d
   266       500        299.0      0.6      0.0          if args.commE:
   267                                                       # single batch loader
   268                                                       seldata_idx = random.sample(range(len(partitioned)), k=int(min(args.bs, len(partitioned))))
   269                                                       partitioned = torch.utils.data.Subset(partitioned, indices=seldata_idx)
   270                                           
   271      1000      15886.0     15.9      0.1          train_loader = torch.utils.data.DataLoader(partitioned,
   272       500        536.0      1.1      0.0                                                     batch_size=len(partitioned),
   273       500         30.0      0.1      0.0                                                     shuffle=False,
   274       500         27.0      0.1      0.0                                                     pin_memory=True)
   275                                           
   276                                                   # Compute local loss values or proxies for the clients
   277       500        126.0      0.3      0.0          tmp, total = 0,0
   278      1000       4380.0      4.4      0.0          with torch.no_grad():
   279       500        135.0      0.3      0.0              comptime_start = time.time()
   280      1000   19038857.0  19038.9     98.7              for batch_idx, (data, target) in enumerate(train_loader):
   281       500       1734.0      3.5      0.0                  data = data.to(device, non_blocking=True)
   282       500        255.0      0.5      0.0                  target = target.to(device, non_blocking=True)
   283       500     215656.0    431.3      1.1                  outputs = model(data)
   284       500      12943.0     25.9      0.1                  loss = criterion(outputs, target)
   285       500       1368.0      2.7      0.0                  tmp += loss.item()
   286       500        164.0      0.3      0.0                  total += 1
   287       500        268.0      0.5      0.0              final_loss = tmp/total
   288       500        689.0      1.4      0.0              comptime_end = time.time()
   289       500        435.0      0.9      0.0              client_comptime.append(comptime_end-comptime_start)
   290       500        147.0      0.3      0.0              client_loss.append(final_loss)
   291                                           
   292         5          1.0      0.2      0.0      return client_loss, client_comptime

Total time: 7.9862 s
File: trainer.py
Function: evaluate at line 294

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   294                                           @profile
   295                                           def evaluate(model, test_loader, criterion):
   296                                               """
   297                                               Evaluate test accuracy
   298                                               Evaluate model on full test dataset
   299                                               """
   300                                           
   301         5        148.0     29.6      0.0      model.eval()
   302         5          0.0      0.0      0.0      loss, total, correct = 0.0, 0.0, 0.0
   303                                           
   304                                               # Get test accuracy for the current model
   305        10         69.0      6.9      0.0      with torch.no_grad():
   306       790    7830949.0   9912.6     98.1          for batch_idx, (data, target) in enumerate(test_loader):
   307       785       2289.0      2.9      0.0              data = data.to(device, non_blocking = True)
   308       785        550.0      0.7      0.0              target = target.to(device, non_blocking = True)
   309                                           
   310                                                       # Inference
   311       785      94755.0    120.7      1.2              outputs = model(data)
   312       785       7847.0     10.0      0.1              batch_loss = criterion(outputs,target)
   313       785        976.0      1.2      0.0              loss += batch_loss.item()
   314                                           
   315                                                       # Prediction
   316       785      32417.0     41.3      0.4              _, pred_labels = torch.max(outputs,1)
   317       785       2755.0      3.5      0.0              pred_labels = pred_labels.view(-1)
   318       785      13136.0     16.7      0.2              correct += torch.sum(torch.eq(pred_labels.view(-1), target)).item() / len(pred_labels)
   319       785        301.0      0.4      0.0              total += 1
   320                                           
   321         5          5.0      1.0      0.0          acc = (correct / total) * 100
   322         5          2.0      0.4      0.0          los = loss/total
   323                                           
   324         5          0.0      0.0      0.0      return acc, los

