{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pathlib\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.utils.data.distributed\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distoptim import fedavg\n",
    "import models\n",
    "import util_v4_text as util "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args_parser():\n",
    "    def __init__(self, seltype = \"rand\", powd = 30, num_users = 30, epochs = 50000):\n",
    "        self.name = \"default\"\n",
    "        self.backend = \"Gloo\" # \"nccl\" for GPU, \"Gloo\" for CPU\n",
    "        self.model = \"MLP\"\n",
    "        self.num_classes = 10 # number of classes\n",
    "        self.gmf = 0 # global (server) momentum factor\n",
    "        self.num_users = num_users # 30\n",
    "        self.frac = 0.1\n",
    "        self.powd = powd # 6, number of selected subset workers per round\n",
    "        self.alpha = 0.2 # control the non-iidness of dataset\n",
    "        self.seed = 1 # random seed\n",
    "        self.bs = 64 # batch size on each worker/client\n",
    "        self.lr = 0.1 # 0.00002 # client learning rate\n",
    "        self.momentum = 0.0 # ocal (client) momentum factor\n",
    "        self.rounds = 500 # total communication rounds\n",
    "        self.decay = 1 # 1: decay LR, 0: no decay\n",
    "        self.print_freq = 100 # print info frequency\n",
    "        self.size = 3 # number of local workers\n",
    "        self.fracC = 0.03 # fraction of selected workers per round\n",
    "        self.ensize = 100 # number of all workers\n",
    "        self.rank = 0 # the rank of worker\n",
    "        self.rnd_ratio = 0.1 # hyperparameter for afl\n",
    "        self.delete_ratio = 0.75 # hyperparameter for afl\n",
    "        self.save = \"store_true\" # whether save the training results\n",
    "        self.p = \"store_true\" # whether the dataset is partitioned or not\n",
    "        self.NIID = \"store_true\" # whether the dataset is non-iid or not\n",
    "        self.commE = \"store_true\" # activation of $cpow-d$\n",
    "        self.constantE = \"store_true\" # whether all the local workers have an identical number of local epochs or not\n",
    "        self.optimizer  =\"local\" # optimizer name\n",
    "        self.initmethod = \"tcp://\" # init method\n",
    "        self.mu = 0 # mu parameter in fedprox\n",
    "        self.dataset = \"fmnist\" # type of dataset\n",
    "        \n",
    "        self.localE = 30 # number of local epochs\n",
    "        self.epochs = epochs # 15000\n",
    "        self.seltype = seltype # \"rand\"\n",
    "        self.dim = 5\n",
    "        self.eq = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.get_parameter of MLP_text(\n",
      "  (layer_input): Linear(in_features=200, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (layer_hidden1): Linear(in_features=128, out_features=86, bias=True)\n",
      "  (layer_hidden2): Linear(in_features=86, out_features=30, bias=True)\n",
      "  (layer_hidden3): Linear(in_features=30, out_features=2, bias=True)\n",
      "  (logsoftmax): LogSoftmax(dim=1)\n",
      ")>\n",
      "layer_input.weight \n",
      " tensor([[-0.0481, -0.0290,  0.0317,  ..., -0.0486, -0.0539, -0.0147],\n",
      "        [-0.0403, -0.0430, -0.0391,  ...,  0.0311, -0.0173,  0.0686],\n",
      "        [-0.0043, -0.0061,  0.0633,  ..., -0.0603, -0.0112, -0.0675],\n",
      "        ...,\n",
      "        [-0.0331,  0.0185,  0.0659,  ...,  0.0417, -0.0550, -0.0026],\n",
      "        [ 0.0133, -0.0670, -0.0278,  ...,  0.0598, -0.0401,  0.0056],\n",
      "        [ 0.0671, -0.0255, -0.0134,  ...,  0.0013, -0.0040, -0.0328]])\n",
      "layer_input.bias \n",
      " tensor([-0.0001, -0.0090,  0.0419,  0.0255,  0.0440, -0.0594,  0.0555,  0.0097,\n",
      "        -0.0703, -0.0124,  0.0312,  0.0143,  0.0480, -0.0453, -0.0098,  0.0065,\n",
      "         0.0274, -0.0394, -0.0049,  0.0585,  0.0663, -0.0145,  0.0182,  0.0073,\n",
      "         0.0250, -0.0302,  0.0700,  0.0585, -0.0056,  0.0672,  0.0186,  0.0521,\n",
      "        -0.0513, -0.0345,  0.0446, -0.0294, -0.0170, -0.0055, -0.0315,  0.0415,\n",
      "        -0.0317, -0.0022, -0.0483, -0.0544,  0.0666, -0.0292, -0.0608, -0.0116,\n",
      "         0.0141, -0.0569, -0.0081, -0.0648,  0.0600,  0.0475,  0.0272,  0.0055,\n",
      "         0.0641, -0.0424, -0.0567,  0.0041, -0.0397, -0.0619, -0.0482,  0.0599,\n",
      "        -0.0352,  0.0498,  0.0244,  0.0590, -0.0453,  0.0595,  0.0580, -0.0159,\n",
      "        -0.0077,  0.0413,  0.0550, -0.0541,  0.0502,  0.0143,  0.0620,  0.0430,\n",
      "        -0.0014,  0.0341, -0.0105, -0.0227,  0.0366, -0.0161,  0.0041,  0.0084,\n",
      "        -0.0347,  0.0090, -0.0337,  0.0060,  0.0654,  0.0546, -0.0638,  0.0127,\n",
      "         0.0642,  0.0103,  0.0378,  0.0180,  0.0039,  0.0607,  0.0616,  0.0358,\n",
      "         0.0458, -0.0605,  0.0403,  0.0507,  0.0259,  0.0123, -0.0017, -0.0680,\n",
      "        -0.0170, -0.0461,  0.0209,  0.0503,  0.0462, -0.0408, -0.0479, -0.0638,\n",
      "        -0.0204, -0.0092, -0.0276,  0.0072, -0.0663, -0.0252,  0.0179, -0.0420])\n",
      "layer_hidden1.weight \n",
      " tensor([[ 8.4451e-02,  1.3509e-02, -7.4491e-02,  ...,  2.4577e-02,\n",
      "         -8.4905e-03,  7.9718e-02],\n",
      "        [-8.7275e-02, -3.8966e-02,  4.0745e-02,  ...,  5.8275e-03,\n",
      "          1.0505e-05, -1.5227e-02],\n",
      "        [ 9.4840e-03,  2.3301e-02, -2.7571e-02,  ...,  6.1236e-02,\n",
      "          3.9224e-02,  2.7285e-02],\n",
      "        ...,\n",
      "        [-3.7886e-04, -1.0990e-03,  8.3553e-02,  ...,  8.2773e-02,\n",
      "          6.6301e-03, -3.0961e-02],\n",
      "        [-1.4248e-02,  3.7668e-02,  5.8916e-02,  ..., -4.3509e-03,\n",
      "         -2.3122e-02,  4.0538e-03],\n",
      "        [-3.1296e-02,  5.2398e-02, -1.7597e-02,  ...,  6.8445e-02,\n",
      "          6.5205e-02, -4.2313e-02]])\n",
      "layer_hidden1.bias \n",
      " tensor([-0.0713,  0.0463, -0.0101,  0.0817,  0.0395, -0.0449,  0.0071,  0.0311,\n",
      "         0.0715,  0.0768,  0.0612,  0.0818, -0.0581,  0.0393, -0.0713,  0.0658,\n",
      "         0.0041, -0.0391, -0.0464,  0.0879,  0.0073,  0.0876, -0.0683, -0.0482,\n",
      "         0.0154,  0.0388,  0.0347, -0.0322, -0.0392, -0.0070, -0.0393,  0.0664,\n",
      "         0.0068, -0.0282, -0.0060, -0.0045, -0.0491,  0.0789, -0.0380,  0.0544,\n",
      "        -0.0439,  0.0724, -0.0125,  0.0535, -0.0696,  0.0154,  0.0081, -0.0656,\n",
      "         0.0693,  0.0613,  0.0576,  0.0264, -0.0727, -0.0238, -0.0447,  0.0628,\n",
      "         0.0324,  0.0786, -0.0759, -0.0179,  0.0617,  0.0103, -0.0507, -0.0397,\n",
      "        -0.0441, -0.0231,  0.0339, -0.0059,  0.0879,  0.0577,  0.0375,  0.0174,\n",
      "         0.0511, -0.0113,  0.0484,  0.0292, -0.0873,  0.0665,  0.0085,  0.0421,\n",
      "         0.0547, -0.0300,  0.0544,  0.0412, -0.0409,  0.0603])\n",
      "layer_hidden2.weight \n",
      " tensor([[-0.0159,  0.0389, -0.0340,  ...,  0.0513, -0.0757, -0.0164],\n",
      "        [ 0.1000,  0.0408, -0.0678,  ..., -0.0214,  0.0660,  0.0014],\n",
      "        [ 0.0605, -0.0190, -0.0077,  ..., -0.0010,  0.0212,  0.0646],\n",
      "        ...,\n",
      "        [ 0.1059, -0.0632,  0.0633,  ..., -0.0341,  0.0134, -0.0817],\n",
      "        [-0.0065,  0.0414, -0.0536,  ...,  0.0215,  0.0765,  0.1001],\n",
      "        [-0.0059, -0.0932,  0.0404,  ..., -0.0105, -0.0703,  0.0893]])\n",
      "layer_hidden2.bias \n",
      " tensor([-0.0658,  0.0278, -0.0110,  0.0851, -0.0532, -0.0240, -0.0385,  0.0928,\n",
      "         0.0145,  0.0895,  0.0964, -0.0926,  0.0208,  0.0634,  0.0089, -0.0251,\n",
      "         0.0177,  0.0175,  0.0214, -0.0751,  0.0417,  0.0651,  0.0530,  0.0514,\n",
      "        -0.0607, -0.1046,  0.0091, -0.0004,  0.0101,  0.0729])\n",
      "layer_hidden3.weight \n",
      " tensor([[-0.0301,  0.0480, -0.1410,  0.1749,  0.1304,  0.0873,  0.0784, -0.0761,\n",
      "         -0.1135, -0.1609, -0.0642, -0.1414, -0.1546,  0.0804, -0.0202, -0.0952,\n",
      "         -0.0045, -0.0438,  0.1202,  0.0914,  0.1420,  0.0024,  0.1044, -0.1365,\n",
      "         -0.0419, -0.1316,  0.1287, -0.1391,  0.1137,  0.0697],\n",
      "        [ 0.0475, -0.1228, -0.1514, -0.0498,  0.1411, -0.1696,  0.1542, -0.1527,\n",
      "         -0.0064,  0.1056,  0.1506,  0.0217, -0.0815, -0.1363, -0.1413,  0.0913,\n",
      "          0.1221, -0.0530, -0.1732, -0.0337, -0.0263, -0.1229, -0.0257,  0.0612,\n",
      "         -0.0769,  0.1245,  0.0413,  0.1312,  0.0438, -0.0886]])\n",
      "layer_hidden3.bias \n",
      " tensor([0.1826, 0.0615])\n",
      "Total number of parameters 39494\n"
     ]
    }
   ],
   "source": [
    "class MLP_text(nn.Module):\n",
    "    def __init__(self, input_size, dim_hidden1, dim_hidden2, dim_hidden3, dim_out):\n",
    "        super(MLP_text, self).__init__()\n",
    "        self.layer_input = nn.Linear(input_size, dim_hidden1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.layer_hidden1 = nn.Linear(dim_hidden1, dim_hidden2)\n",
    "        self.layer_hidden2 = nn.Linear(dim_hidden2, dim_hidden3)\n",
    "        self.layer_hidden3 = nn.Linear(dim_hidden3, dim_out)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_input(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer_hidden1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer_hidden2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer_hidden3(x)\n",
    "\n",
    "        return self.logsoftmax(x)\n",
    "    \n",
    "Sent_model = MLP_text(input_size=200, dim_hidden1=128, dim_hidden2 = 86, dim_hidden3 = 30, dim_out=2)\n",
    "\n",
    "\n",
    "Sent_model.get_parameter\n",
    "\n",
    "def model_info(model):\n",
    "    \n",
    "    print(Sent_model.get_parameter)\n",
    "    \n",
    "    num_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(name, \"\\n\", param.data)\n",
    "            num_params += param.data.flatten().size()[0]\n",
    "\n",
    "    print(\"Total number of parameters\", num_params)\n",
    "    \n",
    "model_info(Sent_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sent_model\n",
    "A = torch.randn(8, 200)\n",
    "output = Sent_model(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m vector\n\u001b[1;32m     13\u001b[0m vector\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mLongTensor)\n\u001b[0;32m---> 15\u001b[0m vector2 \u001b[38;5;241m=\u001b[39m \u001b[43mvector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "target = torch.Tensor([0, 1, 0, 1, 0, 1, 0, 0])\n",
    "target\n",
    "\n",
    "num_class = 2\n",
    "\n",
    "vector = torch.zeros((target.size()[0]), num_class)\n",
    "\n",
    "for i in range(len(target)):\n",
    "    vector[i, int(target[i])] = 1.0\n",
    "\n",
    "vector\n",
    "\n",
    "vector.type(torch.LongTensor)\n",
    "\n",
    "vector2 = vector.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.8893, -2.5866, -1.2095, -1.0620, -2.0446],\n",
       "         [-3.2653, -1.9882, -1.5745, -1.3263, -1.0432],\n",
       "         [-1.3411, -2.3245, -2.7554, -2.2392, -0.7540]],\n",
       "        grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([1, 0, 4]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.LogSoftmax(dim=1)\n",
    "loss = nn.NLLLoss()\n",
    "# input is of size N x C = 3 x 5\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "# each element in target has to have 0 <= value < C\n",
    "target = torch.tensor([1, 0, 4])\n",
    "\n",
    "output = loss(m(input), target)\n",
    "# output.backward()\n",
    "m(input), target\n",
    "\n",
    "# # 2D loss example (used, for example, with image inputs)\n",
    "# N, C = 5, 4\n",
    "# loss = nn.NLLLoss()\n",
    "# # input is of size N x C x height x width\n",
    "# data = torch.randn(N, 16, 10, 10)\n",
    "# conv = nn.Conv2d(16, C, (3, 3))\n",
    "# m = nn.LogSoftmax(dim=1)\n",
    "# # each element in target has to have 0 <= value < C\n",
    "# target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C)\n",
    "# output = loss(m(conv(data)), target)\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/Power-of-Choice/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/Power-of-Choice/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/Power-of-Choice/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:216\u001b[0m, in \u001b[0;36mNLLLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/Power-of-Choice/venv/lib/python3.10/site-packages/torch/nn/functional.py:2729\u001b[0m, in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2728\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "criterion(vector, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = [\"polarity\", \"id\", \"data\", \"query\", \"user\", \"text\"]\n",
    "traindata = pd.read_csv('Sent140/traindata_sent140.csv', names=cols, encoding='latin-1')\n",
    "testdata = pd.read_csv('Sent140/testdata_sent140.csv', names=cols, encoding='latin-1')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is a CSV with emoticons removed. Data file format has 6 fields:  \n",
    "0 - the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)  \n",
    "1 - the id of the tweet (2087)  \n",
    "2 - the date of the tweet (Sat May 16 23:58:44 UTC 2009)  \n",
    "3 - the query (lyx). If there is no query, then this value is NO_QUERY.  \n",
    "4 - the user that tweeted (robotickilldozr)  \n",
    "5 - the text of the tweet (Lyx is cool)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>data</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity          id                          data     query  \\\n",
       "0         0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3         0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4         0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "traindata[\"polarity\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoC0lEQVR4nO3dfXRU9Z3H8c9MmExMTYgBQ5JjeBArWJHnko3rahBCBA6WbnZbHupSy4J6wBVytgp7RBLoKZRadGuzRU8LtKtZrFvBLbZgACG1BgrBHB7WcgyloockLLJkSLKOY+buHz0ZG/LATJyb/O7l/TpnznHu/c1vvt/7m8t8vDNJPJZlWQIAADCIt68LAAAAuBIBBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgnH59XUBPhMNhnTt3TikpKfJ4PH1dDgAAiIJlWbp8+bKys7Pl9XZ/jcSRAeXcuXPKycnp6zIAAEAPfPDBB7rpppu6HePIgJKSkiLpzw2mpqbGde5QKKQ33nhD06ZNk8/ni+vcJqA/53N7j/TnfG7v0e39Sfb1GAgElJOTE3kf744jA0rbxzqpqam2BJTk5GSlpqa68oVHf87n9h7pz/nc3qPb+5Ps7zGar2fwJVkAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4/Tr6wIAAHCzoSte7+sSYuZPsLRhUt/WwBUUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGCcmH+TbGVlpb7//e+rurpadXV12r59u2bPnh3Z7/F4On3chg0b9O1vf1uSNHToUL3//vvt9q9bt04rVqyItRzbjCrZrWBr572Y6E/rZ/Z1CQAAxE3MV1Cam5s1ZswYlZWVdbq/rq6u3W3z5s3yeDwqKipqN27NmjXtxj366KM96wAAALhOzFdQpk+frunTp3e5PzMzs9391157TZMnT9bNN9/cbntKSkqHsQAAAJLNfyywoaFBr7/+un72s5912Ld+/XqtXbtWgwcP1rx587R8+XL169d5OcFgUMFgMHI/EAhIkkKhkEKhUFxrbpvP77XiOq/doj0ObePifdxM4fb+JPf3SH/O5/YeY+3Pn+Cs9xPps/dAu95jo+GxLKvHR87j8XT4Dspf2rBhg9avX69z584pKSkpsn3jxo0aP3680tPT9fbbb2vlypV68MEHtXHjxk7nKSkpUWlpaYft5eXlSk5O7mn5AACgF7W0tGjevHlqbGxUampqt2NtDSgjR45UQUGBnnvuuW7n2bx5sx566CE1NTXJ7/d32N/ZFZScnBxduHDhqg3GKhQKqaKiQquOeBUMO+dLsidKCqMa19ZfQUGBfD6fzVX1Prf3J7m/R/pzPrf3GGt/o0p290JV8eX3Wlo7MRz3NQwEAho4cGBUAcW2j3h++9vf6tSpU3r55ZevOjY3N1effvqp/vSnP2nEiBEd9vv9/k6Di8/ns+3FHwx7HPVTPLEeBzuPnQnc3p/k/h7pz/nc3mO0/TnpveRK8V7DWOay7feg/PSnP9WECRM0ZsyYq46tqamR1+tVRkaGXeUAAAAHifkKSlNTk2prayP3z5w5o5qaGqWnp2vw4MGS/nwJ55VXXtEPfvCDDo+vqqrSoUOHNHnyZKWkpKiqqkrLly/XN77xDd1www2foxUAAOAWMQeUI0eOaPLkyZH7xcXFkqQFCxZo69atkqRt27bJsizNnTu3w+P9fr+2bdumkpISBYNBDRs2TMuXL4/MAwAAEHNAyc/P19W+V7t48WItXry4033jx4/XwYMHY31aAABwDeFv8QAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwTswBpbKyUrNmzVJ2drY8Ho927NjRbv83v/lNeTyedrf77ruv3ZiLFy9q/vz5Sk1NVVpamhYuXKimpqbP1QgAAHCPmANKc3OzxowZo7Kysi7H3Hfffaqrq4vc/uM//qPd/vnz5+vkyZOqqKjQzp07VVlZqcWLF8dePQAAcKV+sT5g+vTpmj59erdj/H6/MjMzO9337rvvateuXTp8+LAmTpwoSXruuec0Y8YMPf3008rOzo61JAAA4DIxB5Ro7N+/XxkZGbrhhht077336jvf+Y4GDBggSaqqqlJaWloknEjS1KlT5fV6dejQIX31q1/tMF8wGFQwGIzcDwQCkqRQKKRQKBTX2tvm83utuM5rt2iPQ9u4eB83U7i9P8n9PdKf87m9x1j78yc46/1E+uw90K732Gh4LMvq8ZHzeDzavn27Zs+eHdm2bds2JScna9iwYTp9+rT+5V/+Rddff72qqqqUkJCg7373u/rZz36mU6dOtZsrIyNDpaWleuSRRzo8T0lJiUpLSztsLy8vV3Jyck/LBwAAvailpUXz5s1TY2OjUlNTux0b9ysoc+bMifz3HXfcodGjR2v48OHav3+/pkyZ0qM5V65cqeLi4sj9QCCgnJwcTZs27aoNxioUCqmiokKrjngVDHviOredTpQURjWurb+CggL5fD6bq+p9bu9Pcn+P9Od8bu8x1v5Glezuhariy++1tHZiOO5r2PYJSDRs+YjnL918880aOHCgamtrNWXKFGVmZur8+fPtxnz66ae6ePFil99b8fv98vv9Hbb7fD7bXvzBsEfBVucElFiPg53HzgRu709yf4/053xu7zHa/pz0XnKleK9hLHPZ/ntQPvzwQ3300UfKysqSJOXl5enSpUuqrq6OjNm3b5/C4bByc3PtLgcAADhAzFdQmpqaVFtbG7l/5swZ1dTUKD09Xenp6SotLVVRUZEyMzN1+vRpPf7447rllltUWPjnjyBuu+023XfffVq0aJE2bdqkUCikpUuXas6cOfwEDwAAkNSDKyhHjhzRuHHjNG7cOElScXGxxo0bp6eeekoJCQk6duyY7r//ft16661auHChJkyYoN/+9rftPqJ56aWXNHLkSE2ZMkUzZszQXXfdpRdeeCF+XQEAAEeL+QpKfn6+uvvBn927r/5loPT0dJWXl8f61AAA4BrB3+IBAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAME6/vi4AADozqmS3gq2evi4jan9aP7OvSwBchSsoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxok5oFRWVmrWrFnKzs6Wx+PRjh07IvtCoZCeeOIJ3XHHHfrCF76g7Oxs/cM//IPOnTvXbo6hQ4fK4/G0u61fv/5zNwMAANwh5oDS3NysMWPGqKysrMO+lpYWHT16VKtWrdLRo0f16quv6tSpU7r//vs7jF2zZo3q6uoit0cffbRnHQAAANfpF+sDpk+frunTp3e6r3///qqoqGi37Uc/+pEmTZqks2fPavDgwZHtKSkpyszMjPXpAQDANcD276A0NjbK4/EoLS2t3fb169drwIABGjdunL7//e/r008/tbsUAADgEDFfQYnFxx9/rCeeeEJz585VampqZPs//dM/afz48UpPT9fbb7+tlStXqq6uThs3bux0nmAwqGAwGLkfCAQk/fk7L6FQKK41t83n91pxnddu0R6HtnHxPm6mcHt/kvt75Bx0Prf3GGt//gRnvZalz84/u95jo+GxLKvHR87j8Wj79u2aPXt2p0UUFRXpww8/1P79+9sFlCtt3rxZDz30kJqamuT3+zvsLykpUWlpaYft5eXlSk5O7mn5AACgF7W0tGjevHlqbGzsNhdINgWUUCikr33ta/rjH/+offv2acCAAd3Oc/LkSY0aNUp/+MMfNGLEiA77O7uCkpOTowsXLly1wViFQiFVVFRo1RGvgmFPXOe204mSwqjGtfVXUFAgn89nc1W9z+39Se7vkXPQ+dzeY6z9jSrZ3QtVxZffa2ntxHDc1zAQCGjgwIFRBZS4f8TTFk7ee+89vfnmm1cNJ5JUU1Mjr9erjIyMTvf7/f5Or6z4fD7bXvzBsEfBVuf84xjrcbDz2JnA7f1J7u+Rc9D53N5jtP056XV8pXivYSxzxRxQmpqaVFtbG7l/5swZ1dTUKD09XVlZWfq7v/s7HT16VDt37lRra6vq6+slSenp6UpMTFRVVZUOHTqkyZMnKyUlRVVVVVq+fLm+8Y1v6IYbboi1HAAA4EIxB5QjR45o8uTJkfvFxcWSpAULFqikpET/9V//JUkaO3Zsu8e9+eabys/Pl9/v17Zt21RSUqJgMKhhw4Zp+fLlkXkAAABiDij5+fnq7msrV/tKy/jx43Xw4MFYnxYAAFxD+Fs8AADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMaJOaBUVlZq1qxZys7Olsfj0Y4dO9rttyxLTz31lLKysnTddddp6tSpeu+999qNuXjxoubPn6/U1FSlpaVp4cKFampq+lyNAAAA94g5oDQ3N2vMmDEqKyvrdP+GDRv0wx/+UJs2bdKhQ4f0hS98QYWFhfr4448jY+bPn6+TJ0+qoqJCO3fuVGVlpRYvXtzzLgAAgKv0i/UB06dP1/Tp0zvdZ1mWnn32WT355JP6yle+Ikn6+c9/rkGDBmnHjh2aM2eO3n33Xe3atUuHDx/WxIkTJUnPPfecZsyYoaefflrZ2dmfox0AAOAGMQeU7pw5c0b19fWaOnVqZFv//v2Vm5urqqoqzZkzR1VVVUpLS4uEE0maOnWqvF6vDh06pK9+9asd5g0GgwoGg5H7gUBAkhQKhRQKheLZQmQ+v9eK67x2i/Y4tI2L93Ezhdv7k9zfI+eg87m9x1j78yc467UsfXb+2fUeG424BpT6+npJ0qBBg9ptHzRoUGRffX29MjIy2hfRr5/S09MjY660bt06lZaWdtj+xhtvKDk5OR6ld7B2YtiWee3y61//OqbxFRUVNlViBrf3J7m/R85B53N7j9H2t2GSzYXYKN5r2NLSEvXYuAYUu6xcuVLFxcWR+4FAQDk5OZo2bZpSU1Pj+lyhUEgVFRVadcSrYNgT17ntdKKkMKpxbf0VFBTI5/PZXFXvc3t/kvt75Bx0Prf3GGt/o0p290JV8eX3Wlo7MRz3NWz7BCQacQ0omZmZkqSGhgZlZWVFtjc0NGjs2LGRMefPn2/3uE8//VQXL16MPP5Kfr9ffr+/w3afz2fbiz8Y9ijY6px/HGM9DnYeOxO4vT/J/T1yDjqf23uMtj8nvY6vFO81jGWuuP4elGHDhikzM1N79+6NbAsEAjp06JDy8vIkSXl5ebp06ZKqq6sjY/bt26dwOKzc3Nx4lgMAABwq5isoTU1Nqq2tjdw/c+aMampqlJ6ersGDB2vZsmX6zne+oy9+8YsaNmyYVq1apezsbM2ePVuSdNttt+m+++7TokWLtGnTJoVCIS1dulRz5szhJ3gAAICkHgSUI0eOaPLkyZH7bd8NWbBggbZu3arHH39czc3NWrx4sS5duqS77rpLu3btUlJSUuQxL730kpYuXaopU6bI6/WqqKhIP/zhD+PQDgAAcIOYA0p+fr4sq+sfmfJ4PFqzZo3WrFnT5Zj09HSVl5fH+tQAAOAawd/iAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGCcuAeUoUOHyuPxdLgtWbJEkpSfn99h38MPPxzvMgAAgIP1i/eEhw8fVmtra+T+iRMnVFBQoL//+7+PbFu0aJHWrFkTuZ+cnBzvMgAAgIPFPaDceOON7e6vX79ew4cP1z333BPZlpycrMzMzHg/NQAAcIm4B5S/9Mknn+jFF19UcXGxPB5PZPtLL72kF198UZmZmZo1a5ZWrVrV7VWUYDCoYDAYuR8IBCRJoVBIoVAorjW3zef3WnGd127RHoe2cfE+bqZwe3+S+3vkHHQ+t/cYa3/+BGe9lqXPzj+73mOj4bEsy7Yj94tf/ELz5s3T2bNnlZ2dLUl64YUXNGTIEGVnZ+vYsWN64oknNGnSJL366qtdzlNSUqLS0tIO28vLy/l4CAAAh2hpadG8efPU2Nio1NTUbsfaGlAKCwuVmJioX/3qV12O2bdvn6ZMmaLa2loNHz680zGdXUHJycnRhQsXrtpgrEKhkCoqKrTqiFfBsOfqDzDEiZLCqMa19VdQUCCfz2dzVb3P7f1J7u+Rc9D53N5jrP2NKtndC1XFl99rae3EcNzXMBAIaODAgVEFFNs+4nn//fe1Z8+ebq+MSFJubq4kdRtQ/H6//H5/h+0+n8+2F38w7FGw1Tn/OMZ6HOw8diZwe3+S+3vkHHQ+t/cYbX9Oeh1fKd5rGMtctv0elC1btigjI0MzZ87sdlxNTY0kKSsry65SAACAw9hyBSUcDmvLli1asGCB+vX77ClOnz6t8vJyzZgxQwMGDNCxY8e0fPly3X333Ro9erQdpQAAAAeyJaDs2bNHZ8+e1be+9a122xMTE7Vnzx49++yzam5uVk5OjoqKivTkk0/aUQYAAHAoWwLKtGnT1Nl3b3NycnTgwAE7nhIAALgIf4sHAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHHiHlBKSkrk8Xja3UaOHBnZ//HHH2vJkiUaMGCArr/+ehUVFamhoSHeZQAAAAez5QrK7bffrrq6usjtrbfeiuxbvny5fvWrX+mVV17RgQMHdO7cOf3t3/6tHWUAAACH6mfLpP36KTMzs8P2xsZG/fSnP1V5ebnuvfdeSdKWLVt022236eDBg/qrv/orO8oBAAAOY8sVlPfee0/Z2dm6+eabNX/+fJ09e1aSVF1drVAopKlTp0bGjhw5UoMHD1ZVVZUdpQAAAAeK+xWU3Nxcbd26VSNGjFBdXZ1KS0v1N3/zNzpx4oTq6+uVmJiotLS0do8ZNGiQ6uvru5wzGAwqGAxG7gcCAUlSKBRSKBSKa/1t8/m9VlzntVu0x6FtXLyPmync3p/k/h45B53P7T3G2p8/wVmvZemz88+u99hoeCzLsvXIXbp0SUOGDNHGjRt13XXX6cEHH2wXNiRp0qRJmjx5sr73ve91OkdJSYlKS0s7bC8vL1dycrItdQMAgPhqaWnRvHnz1NjYqNTU1G7H2vIdlL+UlpamW2+9VbW1tSooKNAnn3yiS5cutbuK0tDQ0Ol3VtqsXLlSxcXFkfuBQEA5OTmaNm3aVRuMVSgUUkVFhVYd8SoY9sR1bjudKCmMalxbfwUFBfL5fDZX1fvc3p/k/h45B53P7T3G2t+okt29UFV8+b2W1k4Mx30N2z4BiYbtAaWpqUmnT5/WAw88oAkTJsjn82nv3r0qKiqSJJ06dUpnz55VXl5el3P4/X75/f4O230+n20v/mDYo2Crc/5xjPU42HnsTOD2/iT398g56Hxu7zHa/pz0Or5SvNcwlrniHlD++Z//WbNmzdKQIUN07tw5rV69WgkJCZo7d6769++vhQsXqri4WOnp6UpNTdWjjz6qvLw8foIHAABExD2gfPjhh5o7d64++ugj3Xjjjbrrrrt08OBB3XjjjZKkZ555Rl6vV0VFRQoGgyosLNS//du/xbsMAADgYHEPKNu2bet2f1JSksrKylRWVhbvpwYAAC7B3+IBAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAME7cA8q6dev05S9/WSkpKcrIyNDs2bN16tSpdmPy8/Pl8Xja3R5++OF4lwIAABwq7gHlwIEDWrJkiQ4ePKiKigqFQiFNmzZNzc3N7cYtWrRIdXV1kduGDRviXQoAAHCofvGecNeuXe3ub926VRkZGaqurtbdd98d2Z6cnKzMzMx4Pz0AAHCBuAeUKzU2NkqS0tPT221/6aWX9OKLLyozM1OzZs3SqlWrlJyc3OkcwWBQwWAwcj8QCEiSQqGQQqFQXOttm8/vteI6r92iPQ5t4+J93Ezh9v4k9/fIOeh8bu8x1v78Cc56LUufnX92vcdGw2NZlm1HLhwO6/7779elS5f01ltvRba/8MILGjJkiLKzs3Xs2DE98cQTmjRpkl599dVO5ykpKVFpaWmH7eXl5V2GGgAAYJaWlhbNmzdPjY2NSk1N7XasrQHlkUce0W9+8xu99dZbuummm7oct2/fPk2ZMkW1tbUaPnx4h/2dXUHJycnRhQsXrtpgrEKhkCoqKrTqiFfBsCeuc9vpRElhVOPa+isoKJDP57O5qt7n9v4k9/fIOeh8bu8x1v5Glezuhariy++1tHZiOO5rGAgENHDgwKgCim0f8SxdulQ7d+5UZWVlt+FEknJzcyWpy4Di9/vl9/s7bPf5fLa9+INhj4KtzvnHMdbjYOexM4Hb+5Pc3yPnoPO5vcdo+3PS6/hK8V7DWOaKe0CxLEuPPvqotm/frv3792vYsGFXfUxNTY0kKSsrK97lAAAAB4p7QFmyZInKy8v12muvKSUlRfX19ZKk/v3767rrrtPp06dVXl6uGTNmaMCAATp27JiWL1+uu+++W6NHj453OQAAwIHiHlB+/OMfS/rzL2P7S1u2bNE3v/lNJSYmas+ePXr22WfV3NysnJwcFRUV6cknn4x3KQAAwKFs+YinOzk5OTpw4EC8nxYAALgIf4sHAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHH6NKCUlZVp6NChSkpKUm5urn7/+9/3ZTkAAMAQfRZQXn75ZRUXF2v16tU6evSoxowZo8LCQp0/f76vSgIAAIbos4CyceNGLVq0SA8++KC+9KUvadOmTUpOTtbmzZv7qiQAAGCIfn3xpJ988omqq6u1cuXKyDav16upU6eqqqqqw/hgMKhgMBi539jYKEm6ePGiQqFQXGsLhUJqaWlRv5BXrWFPXOe200cffRTVuLb+PvroI/l8Ppur6n1u709yf4+cg87n9h5j7a/fp829UFV89QtbamkJx30NL1++LEmyLOvqNcTtWWNw4cIFtba2atCgQe22Dxo0SH/4wx86jF+3bp1KS0s7bB82bJhtNTrNwB/0dQXAtY1zEG4zz8a5L1++rP79+3c7pk8CSqxWrlyp4uLiyP1wOKyLFy9qwIAB8nji+39YgUBAOTk5+uCDD5SamhrXuU1Af87n9h7pz/nc3qPb+5Ps69GyLF2+fFnZ2dlXHdsnAWXgwIFKSEhQQ0NDu+0NDQ3KzMzsMN7v98vv97fblpaWZmeJSk1Nde0LT6I/N3B7j/TnfG7v0e39Sfb0eLUrJ2365EuyiYmJmjBhgvbu3RvZFg6HtXfvXuXl5fVFSQAAwCB99hFPcXGxFixYoIkTJ2rSpEl69tln1dzcrAcffLCvSgIAAIbos4Dy9a9/Xf/zP/+jp556SvX19Ro7dqx27drV4Yuzvc3v92v16tUdPlJyC/pzPrf3SH/O5/Ye3d6fZEaPHiuan/UBAADoRfwtHgAAYBwCCgAAMA4BBQAAGIeAAgAAjHNNBpSysjINHTpUSUlJys3N1e9///tux7/yyisaOXKkkpKSdMcdd+jXv/51L1XaM7H0t3XrVnk8nna3pKSkXqw2NpWVlZo1a5ays7Pl8Xi0Y8eOqz5m//79Gj9+vPx+v2655RZt3brV9jp7Ktb+9u/f32H9PB6P6uvre6fgGK1bt05f/vKXlZKSooyMDM2ePVunTp266uOcdA72pEcnnYc//vGPNXr06Mgv8MrLy9NvfvObbh/jpPWLtT8nrV1n1q9fL4/Ho2XLlnU7ri/W8JoLKC+//LKKi4u1evVqHT16VGPGjFFhYaHOnz/f6fi3335bc+fO1cKFC/XOO+9o9uzZmj17tk6cONHLlUcn1v6kP/+mwLq6usjt/fff78WKY9Pc3KwxY8aorKwsqvFnzpzRzJkzNXnyZNXU1GjZsmX6x3/8R+3evdvmSnsm1v7anDp1qt0aZmRk2FTh53PgwAEtWbJEBw8eVEVFhUKhkKZNm6bm5q7/mJrTzsGe9Cg55zy86aabtH79elVXV+vIkSO699579ZWvfEUnT57sdLzT1i/W/iTnrN2VDh8+rOeff16jR4/udlyfraF1jZk0aZK1ZMmSyP3W1lYrOzvbWrduXafjv/a1r1kzZ85sty03N9d66KGHbK2zp2Ltb8uWLVb//v17qbr4kmRt37692zGPP/64dfvtt7fb9vWvf90qLCy0sbL4iKa/N99805Jk/e///m+v1BRv58+ftyRZBw4c6HKM087BK0XTo5PPQ8uyrBtuuMH6yU9+0uk+p6+fZXXfn1PX7vLly9YXv/hFq6Kiwrrnnnusxx57rMuxfbWG19QVlE8++UTV1dWaOnVqZJvX69XUqVNVVVXV6WOqqqrajZekwsLCLsf3pZ70J0lNTU0aMmSIcnJyrvp/Ck7jpPX7PMaOHausrCwVFBTod7/7XV+XE7XGxkZJUnp6epdjnL6G0fQoOfM8bG1t1bZt29Tc3Nzlnylx8vpF05/kzLVbsmSJZs6c2WFtOtNXa3hNBZQLFy6otbW1w2+rHTRoUJef2dfX18c0vi/1pL8RI0Zo8+bNeu211/Tiiy8qHA7rzjvv1IcfftgbJduuq/ULBAL6v//7vz6qKn6ysrK0adMm/fKXv9Qvf/lL5eTkKD8/X0ePHu3r0q4qHA5r2bJl+uu//muNGjWqy3FOOgevFG2PTjsPjx8/ruuvv15+v18PP/ywtm/fri996UudjnXi+sXSn9PWTpK2bdumo0ePat26dVGN76s17LNfdQ8z5OXltfs/gzvvvFO33Xabnn/+ea1du7YPK0M0RowYoREjRkTu33nnnTp9+rSeeeYZ/fu//3sfVnZ1S5Ys0YkTJ/TWW2/1dSm2ibZHp52HI0aMUE1NjRobG/Wf//mfWrBggQ4cONDlm7jTxNKf09bugw8+0GOPPaaKigrjv8x7TQWUgQMHKiEhQQ0NDe22NzQ0KDMzs9PHZGZmxjS+L/Wkvyv5fD6NGzdOtbW1dpTY67pav9TUVF133XV9VJW9Jk2aZPyb/tKlS7Vz505VVlbqpptu6nask87BvxRLj1cy/TxMTEzULbfcIkmaMGGCDh8+rH/913/V888/32GsE9cvlv6uZPraVVdX6/z58xo/fnxkW2trqyorK/WjH/1IwWBQCQkJ7R7TV2t4TX3Ek5iYqAkTJmjv3r2RbeFwWHv37u3y88W8vLx24yWpoqKi288j+0pP+rtSa2urjh8/rqysLLvK7FVOWr94qampMXb9LMvS0qVLtX37du3bt0/Dhg276mOctoY96fFKTjsPw+GwgsFgp/uctn6d6a6/K5m+dlOmTNHx48dVU1MTuU2cOFHz589XTU1Nh3Ai9eEa2voVXANt27bN8vv91tatW63//u//thYvXmylpaVZ9fX1lmVZ1gMPPGCtWLEiMv53v/ud1a9fP+vpp5+23n33XWv16tWWz+ezjh8/3lctdCvW/kpLS63du3dbp0+ftqqrq605c+ZYSUlJ1smTJ/uqhW5dvnzZeuedd6x33nnHkmRt3LjReuedd6z333/fsizLWrFihfXAAw9Exv/xj3+0kpOTrW9/+9vWu+++a5WVlVkJCQnWrl27+qqFbsXa3zPPPGPt2LHDeu+996zjx49bjz32mOX1eq09e/b0VQvdeuSRR6z+/ftb+/fvt+rq6iK3lpaWyBinn4M96dFJ5+GKFSusAwcOWGfOnLGOHTtmrVixwvJ4PNYbb7xhWZbz1y/W/py0dl258qd4TFnDay6gWJZlPffcc9bgwYOtxMREa9KkSdbBgwcj++655x5rwYIF7cb/4he/sG699VYrMTHRuv32263XX3+9lyuOTSz9LVu2LDJ20KBB1owZM6yjR4/2QdXRafux2itvbT0tWLDAuueeezo8ZuzYsVZiYqJ18803W1u2bOn1uqMVa3/f+973rOHDh1tJSUlWenq6lZ+fb+3bt69vio9CZ71JarcmTj8He9Kjk87Db33rW9aQIUOsxMRE68Ybb7SmTJkSefO2LOevX6z9OWntunJlQDFlDT2WZVn2XqMBAACIzTX1HRQAAOAMBBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGOf/AfkVsgtrzVc6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testdata[\"polarity\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(levelname)s - %(message)s', level=logging.INFO)\n",
    "logging.debug('This message should appear on the console')\n",
    "\n",
    "args = Args_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(rank, size):\n",
    "    print(rank, size)\n",
    "    \n",
    "    # initiate experiments folder\n",
    "    save_path = '/users/name/'\n",
    "    fold = 'lr{:.4f}_bs{}_cp{}_a{:.2f}_e{}_r0_n{}_f{:.2f}/'.format(args.lr, args.bs, args.localE, args.alpha, args.seed,\n",
    "                                                                   args.ensize, args.fracC)\n",
    "    if args.commE:\n",
    "        fold = 'com_'+fold\n",
    "    folder_name = save_path+args.name+'/'+fold\n",
    "    file_name = '{}_rr{:.2f}_dr{:.2f}_lr{:.3f}_bs{:d}_cp{:d}_a{:.2f}_e{}_r{}_n{}_f{:.2f}_p{}.csv'.format(args.seltype,\n",
    "                                                     args.rnd_ratio, args.delete_ratio, args.lr, args.bs, args.localE,\n",
    "                                                    args.alpha, args.seed, rank, args.ensize, args.fracC, args.powd)\n",
    "    pathlib.Path(folder_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # initiate log files\n",
    "    saveFileName = folder_name + file_name\n",
    "    args.out_fname = saveFileName\n",
    "    with open(args.out_fname, 'w+') as f:\n",
    "        print('BEGIN-TRAINING\\n' 'World-Size,{ws}\\n' 'Batch-Size,{bs}\\n' 'Epoch,itr,'\n",
    "            'loss,trainloss,avg:Loss,Prec@1,avg:Prec@1,val,trainval,updtime,comptime,seltime,entime'.format(\n",
    "            ws=args.size, bs=args.bs), file=f)\n",
    "\n",
    "    # seed for reproducibility\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # load data\n",
    "    partition, train_loader, test_loader, dataratios, traindata = util.partition_dataset(size, args, 0)\n",
    "\n",
    "    # initialization for client selection\n",
    "    cli_loss, cli_freq, cli_val = np.zeros(args.ensize)+1, np.zeros(args.ensize), np.zeros(args.ensize)\n",
    "\n",
    "    tmp_cli = [torch.tensor(0, dtype=torch.float32).cuda() for _ in range(dist.get_world_size())]\n",
    "    tmp_clifreq = [torch.tensor(0).cuda() for _ in range(dist.get_world_size())]\n",
    "\n",
    "    dist.barrier()\n",
    "    # select client for each round, in total m ranks\n",
    "    send = torch.zeros(args.size, dtype=torch.int32).cuda()\n",
    "    if rank == 0:\n",
    "        replace_param = False\n",
    "        if args.seltype =='rand':\n",
    "            replace_param = True\n",
    "\n",
    "        idxs_users = np.random.choice(args.ensize, size=args.size, replace=replace_param)\n",
    "        send = [torch.tensor(int(ii)).cuda() for ii in idxs_users]\n",
    "    dist.barrier()\n",
    "\n",
    "    for i in range(args.size):\n",
    "        dist.broadcast(tensor=send[i], src=0)\n",
    "    dist.barrier()\n",
    "    sel_idx = int(send[rank])\n",
    "\n",
    "    # define neural nets model, criterion, and optimizer\n",
    "    model = models.MLP_text(input_size=200, dim_hidden1=128, dim_hidden2 = 86, dim_hidden3 = 30, dim_out=args.num_classes).cuda()\n",
    "    criterion = nn.NLLLoss().cuda()\n",
    "\n",
    "    # select optimizer according to algorithm\n",
    "    algorithms = {'fedavg': fedavg}\n",
    "\n",
    "    selected_opt = algorithms[args.optimizer]\n",
    "    optimizer = selected_opt(model.parameters(),\n",
    "                      lr=args.lr,\n",
    "                      gmf=args.gmf, # set to 0\n",
    "                      mu = args.mu, # set to 0\n",
    "                      ratio=dataratios[rank],\n",
    "                      momentum=args.momentum, # set to 0\n",
    "                      nesterov = False,\n",
    "                      weight_decay=1e-4)\n",
    "\n",
    "\n",
    "    for rnd in range(args.rounds):\n",
    "\n",
    "        # Initialize hyperparameters\n",
    "        local_epochs = args.localE\n",
    "        weight = 1/args.size\n",
    "\n",
    "        # Clients locally train for several local epochs\n",
    "        loss_final = 0\n",
    "        dist.barrier()\n",
    "        comm_update_start = time.time()\n",
    "        for t in range(local_epochs):\n",
    "            singlebatch_loader = util.partitiondata_loader(partition, sel_idx, args.bs, traindata)\n",
    "            loss = train_text(model, criterion, optimizer, singlebatch_loader, t)\n",
    "            loss_final += loss/local_epochs\n",
    "        dist.barrier()\n",
    "        comm_update_end = time.time()\n",
    "        update_time = comm_update_end - comm_update_start\n",
    "\n",
    "        # Getting value function for client selection (required only for 'rpow-d', 'afl')\n",
    "        dist.barrier()      # TODO: implement multi-arm bandit\n",
    "        dist.all_gather(tmp_cli, torch.tensor(loss_final).cuda())\n",
    "        dist.all_gather(tmp_clifreq, torch.tensor(int(sel_idx)).cuda())\n",
    "        dist.barrier()\n",
    "        for i, i_val in enumerate(tmp_clifreq):\n",
    "            cli_freq[i_val.item()]+= 1         # Cli freq is the entire clients that are selected for all rounds\n",
    "            cli_val[i_val.item()] = tmp_cli[i].item()\n",
    "        not_visited = np.where(cli_freq == 0)[0]\n",
    "\n",
    "        for ii in not_visited:\n",
    "            if args.seltype == 'afl':\n",
    "                cli_val[ii] = -np.inf\n",
    "            else:\n",
    "                cli_val[ii] = np.inf\n",
    "\n",
    "        # synchronize parameters\n",
    "        dist.barrier()\n",
    "        optimizer.average(weight=weight)\n",
    "        dist.barrier()\n",
    "\n",
    "        # evaluate test accuracy\n",
    "        test_acc, test_loss = evaluate(model, test_loader, criterion)\n",
    "\n",
    "        # evaluate loss values and sync selected frequency\n",
    "        cli_loss, cli_comptime = evaluate_client(model, criterion, partition, traindata)\n",
    "        train_loss = sum([cli_loss[i]*dataratios[i] for i in range(args.ensize)])\n",
    "        train_loss1 = sum(cli_loss)/args.ensize\n",
    "\n",
    "        dist.barrier()\n",
    "\n",
    "        # Select client for each round, in total m ranks\n",
    "        send = torch.zeros(args.size, dtype=torch.int32).cuda()\n",
    "        comp_time, sel_time = 0, 0\n",
    "\n",
    "        if rank == 0:\n",
    "            sel_time_start = time.time()\n",
    "            idxs_users, rnd_idx = util.sel_client(dataratios, cli_loss, cli_val, args, rnd)\n",
    "            sel_time_end = time.time()\n",
    "            sel_time = sel_time_end - sel_time_start\n",
    "\n",
    "            if args.seltype == 'pow-d' or args.seltype == 'pow-dint':\n",
    "                comp_time = max([cli_comptime[int(i)] for i in rnd_idx])\n",
    "\n",
    "            send = [torch.tensor(int(ii)).cuda() for ii in idxs_users]\n",
    "        dist.barrier()\n",
    "        for i in range(args.size):\n",
    "            dist.broadcast(tensor=send[i], src=0)\n",
    "        dist.barrier()\n",
    "        sel_idx = int(send[rank])\n",
    "\n",
    "        # record metrics\n",
    "        logging.info(\"Round {} rank {} test accuracy {:.3f} test loss {:.3f}\".format(rnd, rank, test_acc, test_loss))\n",
    "        with open(args.out_fname, '+a') as f:\n",
    "            print('{ep},{itr},{loss:.4f},{trainloss:.4f},{filler},'\n",
    "                  '{filler},{filler},'\n",
    "                  '{val:.4f},{other:.4f},{updtime:.4f},{comptime:.4f},{seltime:.4f},{entime:.4f}'\n",
    "                  .format(ep=rnd, itr=-1, loss=test_loss, trainloss=train_loss,\n",
    "                          filler=-1, val=test_acc, other=train_loss1, updtime=update_time, comptime=comp_time,\n",
    "                          seltime=sel_time, entime=update_time+comp_time+sel_time), file=f)\n",
    "\n",
    "\n",
    "def evaluate_client(model, criterion, partition, traindata):\n",
    "\n",
    "    '''\n",
    "    Evaluating each client's local loss values for the current global model for client selection\n",
    "    :param model: current global model\n",
    "    :param criterion: loss function\n",
    "    :param partition: dataset dict for clients\n",
    "    :return: cli_loss = list of local loss values, cli_comptime = list of computation time\n",
    "    '''\n",
    "\n",
    "    cli_comptime, cli_loss = [], []\n",
    "    model.eval()\n",
    "\n",
    "    # Get data from client to evaluate local loss on\n",
    "    for i in range(args.ensize):\n",
    "        partitioned = partition[i]\n",
    "\n",
    "        # cpow-d\n",
    "        if args.commE:\n",
    "            seldata_idx = random.sample(range(len(partitioned)), k=int(min(args.bs, len(partitioned))))\n",
    "        else:\n",
    "            seldata_idx = partitioned\n",
    "\n",
    "        other = torch.utils.data.Subset(traindata, indices=seldata_idx)\n",
    "        train_loader = torch.utils.data.DataLoader(other, batch_size=args.bs, shuffle=False,\n",
    "                                                    pin_memory=True)\n",
    "\n",
    "        # Compute local loss values or proxies for the clients\n",
    "        tmp, total = 0,0\n",
    "        with torch.no_grad():\n",
    "            comptime_start = time.time()\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                data = data.cuda(non_blocking=True)\n",
    "                target = target.cuda(non_blocking=True)\n",
    "                vec_target = vector_encoding(args.num_classes, target)\n",
    "\n",
    "                vec_target = vec_target.cuda(non_blocking=True)\n",
    "                vec_target = torch.cuda.LongTensor(vec_target.type(torch.cuda.LongTensor))\n",
    "\n",
    "                outputs = model(data)\n",
    "                loss = criterion(outputs, vec_target)\n",
    "                tmp += loss.item()\n",
    "                total += 1\n",
    "\n",
    "            final_loss = tmp/total\n",
    "            comptime_end = time.time()\n",
    "            cli_comptime.append(comptime_end-comptime_start)\n",
    "            cli_loss.append(final_loss)\n",
    "\n",
    "    return cli_loss, cli_comptime\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, criterion):\n",
    "\n",
    "    \"\"\"\n",
    "    Evaluate test accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    loss, total, correct = 0.0, 0.0, 0.0\n",
    "\n",
    "    # Get test accuracy for the current model\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "\n",
    "            data = data.cuda(non_blocking=True)\n",
    "            target = target.cuda(non_blocking=True)\n",
    "            vec_target = vector_encoding(args.num_classes, target)\n",
    "\n",
    "            vec_target = vec_target.cuda(non_blocking=True)\n",
    "            vec_target = torch.cuda.LongTensor(vec_target.type(torch.cuda.LongTensor))\n",
    "\n",
    "            # Inference\n",
    "            outputs = model(data)\n",
    "            batch_loss = criterion(outputs, vec_target)\n",
    "            loss += batch_loss.item()\n",
    "\n",
    "            # Prediction\n",
    "            _, pred_labels = torch.max(outputs,1)\n",
    "            correct += torch.sum(torch.eq(pred_labels, vec_target)).item() / len(pred_labels)\n",
    "            total += 1\n",
    "\n",
    "        acc = (correct / total) * 100\n",
    "        los = loss/total\n",
    "\n",
    "    return acc, los\n",
    "\n",
    "\n",
    "def train_text(model, criterion, optimizer, loader, epoch):\n",
    "    \"\"\"\n",
    "    train model on the sampled mini-batch for $\\tau$ epochs\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    loss, total, correct = 0.0, 0.0, 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        # data loading\n",
    "        data = data.cuda(non_blocking = True)\n",
    "        target = target.cuda(non_blocking = True)\n",
    "        vec_target = vector_encoding(args.num_classes, target)\n",
    "\n",
    "        vec_target = vec_target.cuda(non_blocking = True)\n",
    "        vec_target = torch.cuda.LongTensor(vec_target.type(torch.cuda.LongTensor))\n",
    "        output = model(data)\n",
    "        batch_loss = criterion(output, vec_target)\n",
    "\n",
    "        # backward pass\n",
    "        batch_loss.backward()\n",
    "\n",
    "        # gradient clipping\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10, norm_type=2)\n",
    "\n",
    "        # gradient step\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # write log files\n",
    "        loss += batch_loss.item()\n",
    "\n",
    "        # Prediction\n",
    "        _, pred_labels = torch.max(output, 1)\n",
    "        correct += torch.sum(torch.eq(pred_labels, vec_target)).item()/len(pred_labels)\n",
    "        total += 1\n",
    "\n",
    "        acc = (correct / total)*100\n",
    "        los = loss / total\n",
    "\n",
    "        if batch_idx % args.print_freq == 0 and args.save:\n",
    "            logging.debug('epoch {} itr {}, '\n",
    "                         'rank {}, loss value {:.4f}, train accuracy {:.3f}'\n",
    "                         .format(epoch, batch_idx, rank, los, acc))\n",
    "\n",
    "            with open(args.out_fname, '+a') as f:\n",
    "                print('{ep},{itr},'\n",
    "                      '{loss:.4f},-1,-1,'\n",
    "                      '{top1:.3f},-1,-1,-1,-1,-1,-1'\n",
    "                      .format(ep=epoch, itr=batch_idx,\n",
    "                              loss=los, top1=acc), file=f)\n",
    "\n",
    "    with open(args.out_fname, '+a') as f:\n",
    "        print('{ep},{itr},'\n",
    "              '{loss:.4f},-1,-1,'\n",
    "              '{top1:.3f},-1,-1,-1,-1,-1,-1'\n",
    "              .format(ep=epoch, itr=batch_idx,\n",
    "                      loss=los, top1=acc), file=f)\n",
    "\n",
    "    return los\n",
    "\n",
    "\n",
    "def init_processes(rank, size, fn):\n",
    "    \"\"\" Initialize the distributed environment. \"\"\"\n",
    "    os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "    os.environ['MASTER_PORT'] = '29500'\n",
    "    dist.init_process_group(backend= args.backend, \n",
    "                            # init_method= \"spawn://\", #args.initmethod, \n",
    "                            rank=rank, \n",
    "                            world_size=size)\n",
    "    fn(rank, size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(rank, size):\n",
    "    print(rank, size)\n",
    "    \n",
    "def init_processes(rank, size, fn):\n",
    "    \"\"\" Initialize the distributed environment. \"\"\"\n",
    "    os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "    os.environ['MASTER_PORT'] = '29500'\n",
    "    dist.init_process_group(backend= args.backend, \n",
    "                            # init_method= \"spawn://\", #args.initmethod, \n",
    "                            rank=rank, \n",
    "                            world_size=size)\n",
    "#     fn(rank, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = args.rank\n",
    "size = args.size\n",
    "\n",
    "# os.environ['MASTER_ADDR'] = \"Localhost\" # '127.0.0.1'\n",
    "# os.environ['MASTER_PORT'] = '29500'\n",
    "\n",
    "dist.init_process_group(backend= args.backend, \n",
    "                        init_method= \"file:///root/workspace/Power-of-Choice/MLP_sentiment_analysis_Twitter/test/sharedfile\", # \"spawn://\", #args.initmethod, \n",
    "                        rank=rank, \n",
    "                        world_size=size)\n",
    "\n",
    "# init_processes(rank, size, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.distributed.is_available(), torch.distributed.is_initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"run.py:\"\"\"\n",
    "# !/usr/bin/env python\n",
    "import os\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "def run(rank, size):\n",
    "    \"\"\" Distributed function to be implemented later. \"\"\"\n",
    "    pass\n",
    "\n",
    "def init_process(rank, size, fn):\n",
    "    \"\"\" Initialize the distributed environment. \"\"\"\n",
    "    os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "    os.environ['MASTER_PORT'] = '29500'\n",
    "    dist.init_process_group(backend='gloo', rank=rank, world_size=size)\n",
    "    fn(rank, size)\n",
    "\n",
    "\n",
    "\n",
    "size = 2\n",
    "processes = []\n",
    "# mp.set_start_method(\"spawn\")\n",
    "for rank in range(size):\n",
    "    p = mp.Process(target=init_process, args=(rank, size, run))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "\n",
    "for p in processes:\n",
    "    p.join()\n",
    "    \n",
    "dist\n",
    "\n",
    "# init_process(1, 2, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# arr = np.random.rand(10000, 10000)\n",
    "\n",
    "# arr.itemsize*arr.size / 1e6\n",
    "\n",
    "# arr @ arr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
