{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8d279705-65f1-44bc-9cdb-04d3ab641dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import time\n",
    "import pathlib\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.backends.cudnn as cudnn\n",
    "\n",
    "from distoptim import fedavg\n",
    "import util_text as util\n",
    "import models\n",
    "# from params import args_parser\n",
    "\n",
    "# define device\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\" # GPU does not speed up training here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e72fd96d-b798-44aa-8280-9d800ba1c7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Repository initialized!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/363474a791ea4ebf8b0e375509b6c86a', creation_time=1700855979430, experiment_id='4', last_update_time=1700855979430, lifecycle_stage='active', name='Twitter_Sentiment_Analysis', tags={}>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import dagshub\n",
    "from mlflow.models import infer_signature\n",
    "dagshub.init(repo_owner='peng-ju', repo_name='Power-of-Choice', mlflow=True)\n",
    "mlflow.set_tracking_uri=\"https://dagshub.com/peng-ju/Power-of-Choice.mlflow\"\n",
    "mlflow.set_experiment(experiment_name=\"Twitter_Sentiment_Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ea0cce8e-ea26-4fff-b5db-074c2a124e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args_parser():\n",
    "    def __init__(self):\n",
    "        self.name = \"20231125\"\n",
    "        self.model = \"MLP\"\n",
    "        self.alpha = 0.2\n",
    "        self.num_classes = 1\n",
    "        self.lr = 0.05\n",
    "        self.momentum = 0\n",
    "        self.bs = 32\n",
    "        self.rounds = 150\n",
    "        self.localE = 100\n",
    "        self.decay = 1 # 1: decay LR, 0: no decay\n",
    "        self.size = 8 # 8, selected clients for updating the model: m\n",
    "        self.powd = 50 # 32\n",
    "        self.fracC = 0.2\n",
    "        self.seltype = \"rpow-d\" # pow-d, rand, afl, rpow-d(d=50)\n",
    "        self.ensize = 314\n",
    "        self.rank = 0\n",
    "        self.rnd_ratio = 0.1\n",
    "        self.delete_ratio = 0.75\n",
    "        self.seed = 1\n",
    "        self.commE = \"store_true\"\n",
    "        self.constant = \"store_true\"\n",
    "        self.dataset = \"twitter\"\n",
    "        self.minimum_tweets = 32 # \n",
    "\n",
    "args = Args_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f75e377e-3e40-49b9-a0c7-6266bf0e04ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin load Glove twitter embedding \n",
      "\n",
      "finish load Glove twitter embedding \n",
      "\n",
      "Randomly select 314 users from  2503  candidates\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "partition, train_loader, test_loader, dataratios, traindata = util.partition_dataset(args.size, args, 0)\n",
    "# print(\"\\n dataratios: \", dataratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "50b71d44-6174-489e-a158-1b6453e00fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(levelname)s - %(message)s', level=logging.INFO)\n",
    "logging.debug('This message should appear on the console')\n",
    "\n",
    "def run(args):\n",
    "    rank = args.rank\n",
    "    size = args.size\n",
    "    print(\"run start \\n\")\n",
    "    # initiate experiments folder\n",
    "    save_path = './logs/'\n",
    "    fold = 'lr{:.4f}_bs{}_cp{}_a{:.2f}_e{}_r0_n{}_f{:.2f}/'.format(args.lr, \n",
    "                                                                   args.bs, \n",
    "                                                                   args.localE, \n",
    "                                                                   args.alpha, \n",
    "                                                                   args.seed,\n",
    "                                                                   args.ensize, \n",
    "                                                                   args.fracC)\n",
    "    if args.commE:\n",
    "        fold = 'com_'+fold\n",
    "    folder_name = save_path+args.name+'/'+fold\n",
    "    file_name = '{}_rr{:.2f}_dr{:.2f}_lr{:.3f}_bs{:d}_cp{:d}_a{:.2f}_e{}_r{}_n{}_f{:.2f}_p{}.csv'.format(args.seltype,\n",
    "                                                                                                         args.rnd_ratio, \n",
    "                                                                                                         args.delete_ratio, \n",
    "                                                                                                         args.lr, \n",
    "                                                                                                         args.bs, \n",
    "                                                                                                         args.localE,\n",
    "                                                                                                         args.alpha, \n",
    "                                                                                                         args.seed, \n",
    "                                                                                                         rank, \n",
    "                                                                                                         args.ensize, \n",
    "                                                                                                         args.fracC, \n",
    "                                                                                                         args.powd)\n",
    "                                                    \n",
    "    pathlib.Path(folder_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # initiate log files\n",
    "    saveFileName = folder_name + file_name\n",
    "    args.out_fname = saveFileName\n",
    "    with open(args.out_fname, 'w+') as f:\n",
    "        print('Epoch,itr,loss,trainloss,avg:Loss,Prec@1,avg:Prec@1,val,trainval,updtime,comptime,seltime,entime,testacc,testloss', file=f)\n",
    "\n",
    "    # seed for reproducibility\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"Sentiment_Analysis_seltype_{args.seltype}_powd_{args.powd}_num_users_{args.ensize}_rounds_{args.rounds}\") as run:\n",
    "        # MLflow\n",
    "        params = {}\n",
    "        params[\"Client Selection Algorithm\"] = args.seltype\n",
    "        params[\"Total number of clients\"] = args.ensize\n",
    "        params[\"Learning Rate\"] = args.lr\n",
    "        params[\"Batch Size\"] = args.bs\n",
    "        params[\"Total Client Number\"] = args.ensize\n",
    "        params[\"Selected client number m\"] = args.size\n",
    "        params[\"Local iteration number\"] = args.localE\n",
    "        params[\"Powd\"] = args.powd\n",
    "        params[\"Minimum tweets\"] = args.minimum_tweets\n",
    "\n",
    "        # load data\n",
    "        # partition, train_loader, test_loader, dataratios, traindata = util.partition_dataset(size, args, 0)\n",
    "        # print(\"\\n dataratios: \", dataratios)\n",
    "\n",
    "        # tracking client loss values, frequency for each client\n",
    "        # args.ensize -- number of clients\n",
    "        client_freq, client_loss_proxy = np.zeros(args.ensize), np.zeros(args.ensize)\n",
    "\n",
    "        # initialization for client selection\n",
    "        cli_loss, cli_freq, cli_val = np.zeros(args.ensize)+1, np.zeros(args.ensize), np.zeros(args.ensize)\n",
    "\n",
    "        # select client for the 1st round\n",
    "        replace_param = False\n",
    "        if args.seltype =='rand':\n",
    "            replace_param = True\n",
    "\n",
    "        # user id being selected\n",
    "        sel_idx = np.random.choice(args.ensize, size=args.size, replace=replace_param)\n",
    "\n",
    "        # define multilayer perceptron neural network model for sentiment analysis\n",
    "        model = models.MLP_text(input_size=200, dim_hidden1=128, dim_hidden2=86, dim_hidden3=30, dim_out=1).to(device)\n",
    "        \n",
    "        # allocate buffer for global and aggregate parameters\n",
    "        # ref: https://discuss.pytorch.org/t/how-to-assign-an-arbitrary-tensor-to-models-parameter/44082/3\n",
    "        global_parameters = []\n",
    "        aggregate_parameters = []\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                global_parameters.append(param.detach().clone())\n",
    "                aggregate_parameters.append(torch.zeros_like(param)) \n",
    "        \n",
    "        # criterion\n",
    "        # criterion = nn.NLLLoss().to(device)  # for multi-class classifier.\n",
    "        criterion =nn.BCELoss().to(device)  # for binary classifier\n",
    "        params[\"Criterion\"] = \"nn.BCELoss()\"\n",
    "\n",
    "        # select optimizer according to algorithm\n",
    "        optimizer = torch.optim.SGD(model.parameters(), \n",
    "                                    lr=args.lr, \n",
    "                                    momentum=args.momentum, \n",
    "                                    nesterov=False,\n",
    "                                    weight_decay=1e-4)\n",
    "        params[\"Optimizer\"] = \"torch.optim.SGD\"\n",
    "\n",
    "        test_loss_rnd = []\n",
    "        test_accu_rnd = []\n",
    "        train_loss_rnd = []\n",
    "        train_accu_rnd = []\n",
    "\n",
    "\n",
    "        # start communication rounds\n",
    "        for rnd in range(args.rounds):\n",
    "            round_start = time.time()\n",
    "\n",
    "            # (optional) decay learning rate according to round index\n",
    "            # if args.decay == True:\n",
    "            #     # update_learning_rate(optimizer, rnd, args.lr)\n",
    "            #     if rnd == 50:\n",
    "            #         lr = args.lr/2\n",
    "            #         logging.info(\"Updating learning rate to {}\".format(lr))\n",
    "            #         for param_group in optimizer.param_groups:\n",
    "            #             param_group[\"lr\"] = lr\n",
    "\n",
    "            #     if rnd == 100:\n",
    "            #         lr = args.lr/4\n",
    "            #         logging.info(\"Updating learning rate to {}\".format(lr))\n",
    "            #         for param_group in optimizer.param_groups:\n",
    "            #             param_group[\"lr\"] = lr\n",
    "\n",
    "            # zero aggregate parameters for accumulation of local parameters\n",
    "            with torch.no_grad():\n",
    "                for param in aggregate_parameters:\n",
    "                    param.zero_()\n",
    "\n",
    "            # for each client `i`\n",
    "            for i in sel_idx:\n",
    "                # send global parameters to client `i`\n",
    "                with torch.no_grad():\n",
    "                    for param, global_param in zip(model.parameters(), global_parameters):\n",
    "                        param.copy_(global_param)\n",
    "                \n",
    "                # run E steps of SGD on client `i`\n",
    "                loss_final = 0\n",
    "                comm_update_start = time.time()\n",
    "                for t in range(args.localE):\n",
    "                    singlebatch_loader = util.partitiondata_loader(partition, i, args.bs, traindata)\n",
    "                    loss, model = train_text(rank, model, criterion, optimizer, singlebatch_loader, t)\n",
    "                    loss_final += loss/args.localE #average over localE iterations\n",
    "                comm_update_end = time.time()\n",
    "                update_time = comm_update_end - comm_update_start\n",
    "\n",
    "                # send local parameters from client `i` to server for aggregation\n",
    "                with torch.no_grad():\n",
    "                    weight = 1/args.size\n",
    "                    for aggregate_param, param in zip(aggregate_parameters, model.parameters()):\n",
    "                        aggregate_param.add_(param, alpha=weight)\n",
    "                \n",
    "                # update client frequency and loss values\n",
    "                client_freq[i] += 1\n",
    "                client_loss_proxy[i] = loss_final\n",
    "\n",
    "            not_visited = np.where(client_freq == 0)[0]\n",
    "            for j in not_visited:\n",
    "                if args.seltype == \"afl\":\n",
    "                    client_loss_proxy[j] = -np.inf\n",
    "                else:\n",
    "                    client_loss_proxy[j] = np.inf\n",
    "\n",
    "            # update global parameters\n",
    "            with torch.no_grad():\n",
    "                for global_param, aggregate_param in zip(global_parameters, aggregate_parameters):\n",
    "                    global_param.copy_(aggregate_param)\n",
    "\n",
    "            # set model with global parameters\n",
    "            with torch.no_grad():\n",
    "                for param, global_param in zip(model.parameters(), global_parameters):\n",
    "                    param.copy_(global_param)\n",
    "\n",
    "            # evaluate test accuracy\n",
    "            test_acc, test_loss = evaluate(model, test_loader, criterion)\n",
    "\n",
    "            # evaluate loss values and sync selected frequency\n",
    "            cli_loss, cli_comptime = evaluate_client(model, criterion, partition, traindata)\n",
    "            train_loss = sum([cli_loss[i]*dataratios[i] for i in range(args.ensize)])\n",
    "            # train_loss1 = sum(cli_loss)/args.ensize\n",
    "\n",
    "            # select clients for the next round\n",
    "            sel_time, comp_time = 0, 0\n",
    "            sel_time_start = time.time()\n",
    "            \"\"\"\n",
    "            noteL cli_val, rnd are not useful?\n",
    "            \"\"\"\n",
    "            sel_idx, rnd_idx = util.sel_client(dataratios, cli_loss, cli_val, args, rnd)\n",
    "            # print(f\"len rnd_idx {len(rnd_idx)} idxs_users {len(idxs_users)}\")\n",
    "            sel_time_end = time.time()\n",
    "            sel_time = sel_time_end - sel_time_start\n",
    "\n",
    "            if args.seltype == \"pow-d\" or args.seltype == \"pow-dint\":\n",
    "                comp_time = max([cli_comptime[int(i)] for i in rnd_idx])\n",
    "\n",
    "            # record metrics\n",
    "            round_end = time.time()\n",
    "            round_duration = round(round_end - round_start, 1)\n",
    "            logging.info(f\"[{round_duration} s] Round {rnd} rank {rank} test accuracy {test_acc:.3f} test loss {test_loss:.3f} train loss {train_loss:.3f}\")\n",
    "            # MLflow\n",
    "            mlflow.log_metric(key=\"train_loss\", value=train_loss, step=rnd)\n",
    "            # mlflow.log_metric(key=\"train_accurarcy\", value=train_acc, step=rnd)\n",
    "            mlflow.log_metric(key=\"test_loss\", value=test_loss, step=rnd)\n",
    "            mlflow.log_metric(key=\"test_accurarcy\", value=test_acc, step=rnd)\n",
    "\n",
    "            test_loss_rnd.append(test_loss)\n",
    "            test_accu_rnd.append(test_acc)\n",
    "            train_loss_rnd.append(train_loss)\n",
    "            # train_accu_rnd.append(train_acc)\n",
    "            \n",
    "            # itr = -1 for overal result\n",
    "            with open(args.out_fname, '+a') as f:\n",
    "                print('{ep},{itr},{loss:.4f},{trainloss:.4f},{filler},'\n",
    "                    '{filler},{filler},'\n",
    "                    '{val:.4f},{other:.4f},{updtime:.4f},{comptime:.4f},{seltime:.4f},{entime:.4f}, {testacc:.4f}, {testloss:.4f}'\n",
    "                    .format(ep=rnd, itr=-1, loss=test_loss, trainloss=train_loss,\n",
    "                            filler=-1, val=test_acc, other=train_loss, updtime=update_time, comptime=comp_time,\n",
    "                            seltime=sel_time, entime=update_time+comp_time+sel_time, testacc=test_acc, testloss=test_loss), file=f)\n",
    "        \n",
    "        # MLflow\n",
    "        print(params)\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # save model state_dict and upload as artifact\n",
    "        torch.save(model.state_dict(), \"../models/MLP_Senti.pt\")  # torch save model\n",
    "        \n",
    "        # upload mdoel as artifact\n",
    "        mlflow.log_artifact(\"../models/MLP_Senti.pt\")\n",
    "        \n",
    "        # train_loader = torch.utils.data.DataLoader(traindata, batch_size=args.bs, shuffle=False,\n",
    "        #                                             pin_memory=True)\n",
    "        # data, target = next(iter(train_loader))\n",
    "        # signature = infer_signature(data, model(data))\n",
    "        # model_info = mlflow.pyfunc.log_model(python_model=model, \n",
    "        #                                      artifact_path=\"my_model\", \n",
    "        #                                      signature=signature\n",
    "        #                                     )\n",
    "\n",
    "\n",
    "def evaluate_client(model, criterion, partition, traindata):\n",
    "\n",
    "    '''\n",
    "    Evaluating each client's local loss values for the current global model for client selection\n",
    "    :param model: current global model\n",
    "    :param criterion: loss function\n",
    "    :param partition: dataset dict for clients\n",
    "    :return: cli_loss = list of local loss values, cli_comptime = list of computation time\n",
    "    '''\n",
    "\n",
    "    cli_comptime, cli_loss = [], []\n",
    "    model.eval()\n",
    "\n",
    "    # Get data from client to evaluate local loss on\n",
    "    for i in range(args.ensize):\n",
    "        partitioned = partition[i]\n",
    "\n",
    "        # cpow-d\n",
    "        if args.commE:\n",
    "            seldata_idx = random.sample(range(len(partitioned)), k=int(min(args.bs, len(partitioned))))\n",
    "        else:\n",
    "            seldata_idx = partitioned\n",
    "\n",
    "        other = torch.utils.data.Subset(traindata, indices=seldata_idx)\n",
    "        train_loader = torch.utils.data.DataLoader(other, batch_size=args.bs, shuffle=False,\n",
    "                                                    pin_memory=True)\n",
    "        \n",
    "        # Compute local loss values or proxies for the clients\n",
    "        tmp, total = 0,0\n",
    "        with torch.no_grad():\n",
    "            comptime_start = time.time()\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                data = data.to(device,non_blocking=True)\n",
    "                target = target.to(device,non_blocking=True)\n",
    "                vec_target = vector_encoding(target)\n",
    "\n",
    "                vec_target = vec_target.to(device,non_blocking=True)\n",
    "\n",
    "                outputs = model(data)\n",
    "                outputs.to(device)\n",
    "                loss = criterion(outputs, vec_target)\n",
    "                tmp += loss.item()\n",
    "                total += 1\n",
    "\n",
    "            final_loss = tmp/total\n",
    "            comptime_end = time.time()\n",
    "            cli_comptime.append(comptime_end-comptime_start)\n",
    "            cli_loss.append(final_loss)\n",
    "\n",
    "    return cli_loss, cli_comptime\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, criterion):\n",
    "\n",
    "    \"\"\"\n",
    "    Evaluate test accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    loss, total, correct = 0.0, 0.0, 0.0\n",
    "\n",
    "    # Get test accuracy for the current model\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "\n",
    "            data = data.to(device,non_blocking=True)\n",
    "            target = target.to(device,non_blocking=True)\n",
    "            vec_target = vector_encoding(target)\n",
    "\n",
    "            \n",
    "            vec_target = vec_target.to(device,non_blocking=True)\n",
    "\n",
    "            # Inference\n",
    "            outputs = model(data)\n",
    "            outputs.to(device)\n",
    "            batch_loss = criterion(outputs, vec_target)\n",
    "            loss += batch_loss.item()\n",
    "\n",
    "            # Prediction\n",
    "            # _, pred_labels = torch.max(outputs, 1)\n",
    "            pred_labels = get_label(outputs)\n",
    "            correct += torch.sum(torch.eq(pred_labels, vec_target)).item()/len(pred_labels)\n",
    "            total += 1\n",
    "\n",
    "        acc = (correct / total) * 100\n",
    "        los = loss/total\n",
    "\n",
    "    return acc, los\n",
    "\n",
    "\n",
    "def train_text(rank, model, criterion, optimizer, loader, epoch):\n",
    "    \"\"\"\n",
    "    train model on the sampled mini-batch for $\\tau$ epochs\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    loss, total, correct = 0.0, 0.0, 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        # data loading\n",
    "        data = data.to(device,non_blocking = True)\n",
    "        target = target.to(device,non_blocking = True)\n",
    "        # encode target\n",
    "        vec_target = vector_encoding(target)\n",
    "\n",
    "        vec_target = vec_target.to(device,non_blocking = True)\n",
    "        \n",
    "        outputs = model(data)\n",
    "        outputs.to(device)\n",
    "        # print(\"\\n outputs: \", outputs)\n",
    "        # print(\"\\n vec_target: \", vec_target)\n",
    "        batch_loss = criterion(outputs, vec_target)\n",
    "\n",
    "        # backward pass\n",
    "        batch_loss.backward()\n",
    "\n",
    "        # gradient clipping\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10, norm_type=2)\n",
    "\n",
    "        # gradient step\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # write log files\n",
    "        loss += batch_loss.item()\n",
    "\n",
    "        # Prediction\n",
    "        # _, pred_labels = torch.max(outputs, 1)\n",
    "        pred_labels = get_label(outputs)\n",
    "\n",
    "        correct += torch.sum(torch.eq(pred_labels, vec_target)).item()/len(pred_labels)\n",
    "        total += 1\n",
    "\n",
    "        acc = (correct / total)*100\n",
    "        los = loss / total\n",
    "\n",
    "        # if batch_idx % args.print_freq == 0 and args.save:\n",
    "        #     logging.debug('epoch {} itr {}, '\n",
    "        #                  'rank {}, loss value {:.4f}, train accuracy {:.3f}'\n",
    "        #                  .format(epoch, batch_idx, rank, los, acc))\n",
    "\n",
    "        #     with open(args.out_fname, '+a') as f:\n",
    "        #         print('{ep},{itr},'\n",
    "        #               '{loss:.4f},-1,-1,'\n",
    "        #               '{top1:.3f},-1,-1,-1,-1,-1,-1'\n",
    "        #               .format(ep=epoch, itr=batch_idx,\n",
    "        #                       loss=los, top1=acc), file=f)\n",
    "\n",
    "        with open(args.out_fname, '+a') as f:\n",
    "            print('{ep},{itr},'\n",
    "                '{loss:.4f},-1,-1,'\n",
    "                '{top1:.3f},-1,-1,-1,-1,-1,-1'\n",
    "                .format(ep=epoch, \n",
    "                        itr=batch_idx,\n",
    "                        loss=los, \n",
    "                        top1=acc), file=f)\n",
    "\n",
    "    \n",
    "    return los, model\n",
    "\n",
    "def get_label(x):\n",
    "    \"\"\"\n",
    "    x : probability of been positive\n",
    "    return: predicted label\n",
    "    \"\"\"\n",
    "    res = torch.zeros_like(x)\n",
    "    res[x>0.5] = 1\n",
    "    \n",
    "    return res\n",
    "\n",
    "def vector_encoding(target):\n",
    "    \"\"\"\n",
    "    This is a binary classification\n",
    "\n",
    "    # 0 for positive, 1 for negative\n",
    "    \"\"\"\n",
    "    vector = torch.Tensor([1-i.item() for i in target])\n",
    "    # vector = torch.Tensor([i.item() for i in target])\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "91370967-ed33-4957-bd5d-e2abf3a87c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run start \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - [0.9 s] Round 0 rank 0 test accuracy 49.301 test loss 0.693 train loss 0.691\n",
      "INFO - [1.0 s] Round 1 rank 0 test accuracy 49.301 test loss 0.693 train loss 0.688\n",
      "INFO - [0.9 s] Round 2 rank 0 test accuracy 49.301 test loss 0.693 train loss 0.683\n",
      "INFO - [0.9 s] Round 3 rank 0 test accuracy 57.470 test loss 0.688 train loss 0.670\n",
      "INFO - [0.9 s] Round 4 rank 0 test accuracy 57.552 test loss 0.677 train loss 0.605\n",
      "INFO - [1.0 s] Round 5 rank 0 test accuracy 59.649 test loss 0.653 train loss 0.396\n",
      "INFO - [1.0 s] Round 6 rank 0 test accuracy 60.252 test loss 0.712 train loss 0.300\n",
      "INFO - [0.9 s] Round 7 rank 0 test accuracy 61.911 test loss 0.718 train loss 0.255\n",
      "INFO - [1.0 s] Round 8 rank 0 test accuracy 59.731 test loss 0.751 train loss 0.209\n",
      "INFO - [1.0 s] Round 9 rank 0 test accuracy 62.856 test loss 0.855 train loss 0.174\n",
      "INFO - [1.0 s] Round 10 rank 0 test accuracy 61.897 test loss 0.861 train loss 0.155\n",
      "INFO - [0.9 s] Round 11 rank 0 test accuracy 62.856 test loss 0.856 train loss 0.129\n",
      "INFO - [0.9 s] Round 12 rank 0 test accuracy 62.514 test loss 0.904 train loss 0.123\n",
      "INFO - [1.0 s] Round 13 rank 0 test accuracy 63.117 test loss 1.057 train loss 0.110\n",
      "INFO - [0.9 s] Round 14 rank 0 test accuracy 61.033 test loss 1.088 train loss 0.112\n",
      "INFO - [0.9 s] Round 15 rank 0 test accuracy 62.336 test loss 1.145 train loss 0.098\n",
      "INFO - [1.0 s] Round 16 rank 0 test accuracy 62.253 test loss 1.174 train loss 0.096\n",
      "INFO - [1.0 s] Round 17 rank 0 test accuracy 61.554 test loss 1.207 train loss 0.091\n",
      "INFO - [1.0 s] Round 18 rank 0 test accuracy 61.294 test loss 1.298 train loss 0.126\n",
      "INFO - [0.9 s] Round 19 rank 0 test accuracy 61.033 test loss 1.185 train loss 0.092\n",
      "INFO - [0.9 s] Round 20 rank 0 test accuracy 63.295 test loss 1.136 train loss 0.080\n",
      "INFO - [1.0 s] Round 21 rank 0 test accuracy 62.856 test loss 1.214 train loss 0.088\n",
      "INFO - [1.0 s] Round 22 rank 0 test accuracy 62.253 test loss 1.285 train loss 0.098\n",
      "INFO - [0.9 s] Round 23 rank 0 test accuracy 60.430 test loss 1.338 train loss 0.079\n",
      "INFO - [1.0 s] Round 24 rank 0 test accuracy 59.992 test loss 1.380 train loss 0.079\n",
      "INFO - [1.0 s] Round 25 rank 0 test accuracy 62.171 test loss 1.408 train loss 0.082\n",
      "INFO - [1.0 s] Round 26 rank 0 test accuracy 62.171 test loss 1.464 train loss 0.094\n",
      "INFO - [1.0 s] Round 27 rank 0 test accuracy 60.691 test loss 1.110 train loss 0.077\n",
      "INFO - [1.0 s] Round 28 rank 0 test accuracy 61.212 test loss 1.359 train loss 0.072\n",
      "INFO - [1.0 s] Round 29 rank 0 test accuracy 60.609 test loss 1.192 train loss 0.062\n",
      "INFO - [0.9 s] Round 30 rank 0 test accuracy 62.514 test loss 1.399 train loss 0.059\n",
      "INFO - [0.9 s] Round 31 rank 0 test accuracy 58.868 test loss 1.311 train loss 0.059\n",
      "INFO - [1.1 s] Round 32 rank 0 test accuracy 60.170 test loss 1.559 train loss 0.048\n",
      "INFO - [1.1 s] Round 33 rank 0 test accuracy 58.868 test loss 1.476 train loss 0.076\n",
      "INFO - [1.1 s] Round 34 rank 0 test accuracy 60.430 test loss 1.299 train loss 0.058\n",
      "INFO - [1.0 s] Round 35 rank 0 test accuracy 59.306 test loss 1.451 train loss 0.054\n",
      "INFO - [1.0 s] Round 36 rank 0 test accuracy 57.826 test loss 1.317 train loss 0.045\n",
      "INFO - [1.0 s] Round 37 rank 0 test accuracy 61.993 test loss 1.399 train loss 0.044\n",
      "INFO - [1.0 s] Round 38 rank 0 test accuracy 59.910 test loss 1.370 train loss 0.043\n",
      "INFO - [1.1 s] Round 39 rank 0 test accuracy 61.650 test loss 1.409 train loss 0.044\n",
      "INFO - [1.0 s] Round 40 rank 0 test accuracy 60.430 test loss 1.608 train loss 0.054\n",
      "INFO - [1.0 s] Round 41 rank 0 test accuracy 60.430 test loss 1.686 train loss 0.060\n",
      "INFO - [1.0 s] Round 42 rank 0 test accuracy 62.870 test loss 1.318 train loss 0.043\n",
      "INFO - [1.0 s] Round 43 rank 0 test accuracy 62.089 test loss 1.333 train loss 0.049\n",
      "INFO - [0.9 s] Round 44 rank 0 test accuracy 60.252 test loss 1.130 train loss 0.044\n",
      "INFO - [1.0 s] Round 45 rank 0 test accuracy 60.691 test loss 1.538 train loss 0.058\n",
      "INFO - [1.0 s] Round 46 rank 0 test accuracy 62.952 test loss 1.383 train loss 0.047\n",
      "INFO - [0.9 s] Round 47 rank 0 test accuracy 59.471 test loss 1.359 train loss 0.029\n",
      "INFO - [1.0 s] Round 48 rank 0 test accuracy 62.171 test loss 1.214 train loss 0.046\n",
      "INFO - [0.9 s] Round 49 rank 0 test accuracy 61.732 test loss 1.318 train loss 0.040\n",
      "INFO - [1.0 s] Round 50 rank 0 test accuracy 60.951 test loss 1.624 train loss 0.048\n",
      "INFO - [1.0 s] Round 51 rank 0 test accuracy 61.212 test loss 1.722 train loss 0.051\n",
      "INFO - [1.0 s] Round 52 rank 0 test accuracy 61.472 test loss 1.776 train loss 0.047\n",
      "INFO - [1.0 s] Round 53 rank 0 test accuracy 61.732 test loss 1.813 train loss 0.055\n",
      "INFO - [1.0 s] Round 54 rank 0 test accuracy 62.610 test loss 1.308 train loss 0.027\n",
      "INFO - [1.0 s] Round 55 rank 0 test accuracy 59.992 test loss 1.384 train loss 0.032\n",
      "INFO - [1.0 s] Round 56 rank 0 test accuracy 58.950 test loss 1.371 train loss 0.029\n",
      "INFO - [1.2 s] Round 57 rank 0 test accuracy 60.513 test loss 1.646 train loss 0.038\n",
      "INFO - [1.6 s] Round 58 rank 0 test accuracy 60.252 test loss 1.734 train loss 0.045\n",
      "INFO - [1.2 s] Round 59 rank 0 test accuracy 61.732 test loss 1.625 train loss 0.039\n",
      "INFO - [1.3 s] Round 60 rank 0 test accuracy 63.130 test loss 1.413 train loss 0.023\n",
      "INFO - [1.2 s] Round 61 rank 0 test accuracy 60.951 test loss 1.662 train loss 0.039\n",
      "INFO - [1.1 s] Round 62 rank 0 test accuracy 61.828 test loss 1.441 train loss 0.017\n",
      "INFO - [1.1 s] Round 63 rank 0 test accuracy 60.513 test loss 1.677 train loss 0.025\n",
      "INFO - [1.0 s] Round 64 rank 0 test accuracy 59.211 test loss 1.240 train loss 0.030\n",
      "INFO - [1.0 s] Round 65 rank 0 test accuracy 60.513 test loss 1.630 train loss 0.026\n",
      "INFO - [1.0 s] Round 66 rank 0 test accuracy 60.252 test loss 1.749 train loss 0.030\n",
      "INFO - [1.1 s] Round 67 rank 0 test accuracy 60.691 test loss 1.577 train loss 0.023\n",
      "INFO - [1.1 s] Round 68 rank 0 test accuracy 61.746 test loss 1.418 train loss 0.033\n",
      "INFO - [1.2 s] Round 69 rank 0 test accuracy 60.691 test loss 1.666 train loss 0.029\n",
      "INFO - [1.1 s] Round 70 rank 0 test accuracy 60.430 test loss 1.755 train loss 0.026\n",
      "INFO - [1.0 s] Round 71 rank 0 test accuracy 60.691 test loss 1.810 train loss 0.043\n",
      "INFO - [1.0 s] Round 72 rank 0 test accuracy 60.430 test loss 1.671 train loss 0.047\n",
      "INFO - [1.1 s] Round 73 rank 0 test accuracy 61.212 test loss 1.777 train loss 0.023\n",
      "INFO - [1.1 s] Round 74 rank 0 test accuracy 62.089 test loss 1.518 train loss 0.025\n",
      "INFO - [1.1 s] Round 75 rank 0 test accuracy 60.951 test loss 1.724 train loss 0.043\n",
      "INFO - [1.0 s] Round 76 rank 0 test accuracy 60.170 test loss 1.663 train loss 0.037\n",
      "INFO - [1.1 s] Round 77 rank 0 test accuracy 62.349 test loss 1.529 train loss 0.023\n",
      "INFO - [1.1 s] Round 78 rank 0 test accuracy 60.170 test loss 1.715 train loss 0.027\n",
      "INFO - [1.0 s] Round 79 rank 0 test accuracy 61.390 test loss 1.555 train loss 0.032\n",
      "INFO - [1.0 s] Round 80 rank 0 test accuracy 60.691 test loss 1.726 train loss 0.026\n",
      "INFO - [1.0 s] Round 81 rank 0 test accuracy 59.471 test loss 1.464 train loss 0.030\n",
      "INFO - [1.0 s] Round 82 rank 0 test accuracy 61.212 test loss 1.686 train loss 0.027\n",
      "INFO - [1.0 s] Round 83 rank 0 test accuracy 61.212 test loss 1.769 train loss 0.024\n",
      "INFO - [1.0 s] Round 84 rank 0 test accuracy 61.129 test loss 1.575 train loss 0.022\n",
      "INFO - [1.2 s] Round 85 rank 0 test accuracy 59.910 test loss 1.631 train loss 0.028\n",
      "INFO - [1.1 s] Round 86 rank 0 test accuracy 60.430 test loss 1.649 train loss 0.030\n",
      "INFO - [1.3 s] Round 87 rank 0 test accuracy 62.788 test loss 1.559 train loss 0.022\n",
      "INFO - [1.5 s] Round 88 rank 0 test accuracy 60.951 test loss 1.711 train loss 0.030\n",
      "INFO - [1.0 s] Round 89 rank 0 test accuracy 60.691 test loss 1.759 train loss 0.017\n",
      "INFO - [1.0 s] Round 90 rank 0 test accuracy 60.869 test loss 1.802 train loss 0.034\n",
      "INFO - [0.9 s] Round 91 rank 0 test accuracy 60.869 test loss 1.828 train loss 0.024\n",
      "INFO - [1.0 s] Round 92 rank 0 test accuracy 61.390 test loss 1.846 train loss 0.030\n",
      "INFO - [1.0 s] Round 93 rank 0 test accuracy 62.267 test loss 1.723 train loss 0.015\n",
      "INFO - [1.0 s] Round 94 rank 0 test accuracy 60.526 test loss 1.335 train loss 0.021\n",
      "INFO - [0.9 s] Round 95 rank 0 test accuracy 60.170 test loss 1.697 train loss 0.017\n",
      "INFO - [0.9 s] Round 96 rank 0 test accuracy 60.951 test loss 1.273 train loss 0.022\n",
      "INFO - [1.0 s] Round 97 rank 0 test accuracy 60.869 test loss 1.613 train loss 0.017\n",
      "INFO - [0.9 s] Round 98 rank 0 test accuracy 63.048 test loss 1.351 train loss 0.025\n",
      "INFO - [1.0 s] Round 99 rank 0 test accuracy 60.951 test loss 1.433 train loss 0.015\n",
      "INFO - [1.0 s] Round 100 rank 0 test accuracy 61.650 test loss 1.638 train loss 0.011\n",
      "INFO - [1.2 s] Round 101 rank 0 test accuracy 61.390 test loss 1.732 train loss 0.026\n",
      "INFO - [1.2 s] Round 102 rank 0 test accuracy 59.992 test loss 1.536 train loss 0.012\n",
      "INFO - [1.1 s] Round 103 rank 0 test accuracy 60.869 test loss 1.686 train loss 0.022\n",
      "INFO - [1.4 s] Round 104 rank 0 test accuracy 61.047 test loss 1.563 train loss 0.018\n",
      "INFO - [1.0 s] Round 105 rank 0 test accuracy 60.787 test loss 1.682 train loss 0.017\n",
      "INFO - [1.0 s] Round 106 rank 0 test accuracy 61.047 test loss 1.766 train loss 0.018\n",
      "INFO - [1.0 s] Round 107 rank 0 test accuracy 60.869 test loss 1.817 train loss 0.018\n",
      "INFO - [1.0 s] Round 108 rank 0 test accuracy 60.170 test loss 1.464 train loss 0.021\n",
      "INFO - [1.0 s] Round 109 rank 0 test accuracy 61.212 test loss 1.642 train loss 0.026\n",
      "INFO - [1.0 s] Round 110 rank 0 test accuracy 60.869 test loss 1.577 train loss 0.012\n",
      "INFO - [0.9 s] Round 111 rank 0 test accuracy 60.609 test loss 1.736 train loss 0.019\n",
      "INFO - [1.0 s] Round 112 rank 0 test accuracy 61.129 test loss 1.799 train loss 0.010\n",
      "INFO - [1.0 s] Round 113 rank 0 test accuracy 60.609 test loss 1.853 train loss 0.014\n",
      "INFO - [0.9 s] Round 114 rank 0 test accuracy 61.047 test loss 1.682 train loss 0.022\n",
      "INFO - [1.0 s] Round 115 rank 0 test accuracy 61.047 test loss 1.770 train loss 0.021\n",
      "INFO - [1.1 s] Round 116 rank 0 test accuracy 60.869 test loss 1.831 train loss 0.012\n",
      "INFO - [1.0 s] Round 117 rank 0 test accuracy 60.869 test loss 1.874 train loss 0.029\n",
      "INFO - [1.1 s] Round 118 rank 0 test accuracy 61.129 test loss 1.871 train loss 0.015\n",
      "INFO - [1.0 s] Round 119 rank 0 test accuracy 61.129 test loss 1.909 train loss 0.030\n",
      "INFO - [1.0 s] Round 120 rank 0 test accuracy 61.129 test loss 1.942 train loss 0.008\n",
      "INFO - [1.1 s] Round 121 rank 0 test accuracy 59.731 test loss 1.640 train loss 0.027\n",
      "INFO - [1.1 s] Round 122 rank 0 test accuracy 60.348 test loss 1.533 train loss 0.012\n",
      "INFO - [1.2 s] Round 123 rank 0 test accuracy 60.609 test loss 1.724 train loss 0.013\n",
      "INFO - [1.1 s] Round 124 rank 0 test accuracy 60.609 test loss 1.808 train loss 0.020\n",
      "INFO - [1.5 s] Round 125 rank 0 test accuracy 60.609 test loss 1.561 train loss 0.022\n",
      "INFO - [1.0 s] Round 126 rank 0 test accuracy 61.828 test loss 1.557 train loss 0.011\n",
      "INFO - [1.0 s] Round 127 rank 0 test accuracy 61.568 test loss 1.723 train loss 0.014\n",
      "INFO - [1.0 s] Round 128 rank 0 test accuracy 60.609 test loss 1.778 train loss 0.022\n",
      "INFO - [1.0 s] Round 129 rank 0 test accuracy 60.787 test loss 1.518 train loss 0.013\n",
      "INFO - [1.0 s] Round 130 rank 0 test accuracy 61.047 test loss 1.729 train loss 0.022\n",
      "INFO - [1.0 s] Round 131 rank 0 test accuracy 61.047 test loss 1.811 train loss 0.010\n",
      "INFO - [1.0 s] Round 132 rank 0 test accuracy 61.129 test loss 1.861 train loss 0.020\n",
      "INFO - [1.0 s] Round 133 rank 0 test accuracy 62.185 test loss 1.429 train loss 0.011\n",
      "INFO - [1.0 s] Round 134 rank 0 test accuracy 62.007 test loss 1.493 train loss 0.021\n",
      "INFO - [1.0 s] Round 135 rank 0 test accuracy 61.568 test loss 1.501 train loss 0.019\n",
      "INFO - [1.0 s] Round 136 rank 0 test accuracy 61.828 test loss 1.710 train loss 0.015\n",
      "INFO - [1.0 s] Round 137 rank 0 test accuracy 61.828 test loss 1.795 train loss 0.016\n",
      "INFO - [1.0 s] Round 138 rank 0 test accuracy 61.308 test loss 1.836 train loss 0.017\n",
      "INFO - [1.0 s] Round 139 rank 0 test accuracy 61.568 test loss 1.860 train loss 0.011\n",
      "INFO - [1.0 s] Round 140 rank 0 test accuracy 60.869 test loss 1.901 train loss 0.017\n",
      "INFO - [1.0 s] Round 141 rank 0 test accuracy 61.568 test loss 1.752 train loss 0.013\n",
      "INFO - [1.0 s] Round 142 rank 0 test accuracy 61.568 test loss 1.817 train loss 0.022\n",
      "INFO - [1.1 s] Round 143 rank 0 test accuracy 60.787 test loss 1.870 train loss 0.014\n",
      "INFO - [1.1 s] Round 144 rank 0 test accuracy 62.610 test loss 1.661 train loss 0.014\n",
      "INFO - [1.1 s] Round 145 rank 0 test accuracy 61.129 test loss 1.520 train loss 0.019\n",
      "INFO - [1.0 s] Round 146 rank 0 test accuracy 61.047 test loss 1.304 train loss 0.013\n",
      "INFO - [1.0 s] Round 147 rank 0 test accuracy 62.349 test loss 1.639 train loss 0.016\n",
      "INFO - [1.0 s] Round 148 rank 0 test accuracy 62.870 test loss 1.734 train loss 0.013\n",
      "INFO - [1.0 s] Round 149 rank 0 test accuracy 61.568 test loss 1.561 train loss 0.018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Client Selection Algorithm': 'rpow-d', 'Total number of clients': 314, 'Learning Rate': 0.05, 'Batch Size': 32, 'Total Client Number': 314, 'Selected client number m': 8, 'Local iteration number': 100, 'Powd': 50, 'Minimum tweets': 32, 'Criterion': 'nn.BCELoss()', 'Optimizer': 'torch.optim.SGD'}\n"
     ]
    }
   ],
   "source": [
    "run(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512563c-5b68-4de5-ad86-518a2351d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition, train_loader, test_loader, dataratios, traindata = util.partition_dataset(314, args, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7106b0fb-6dda-4eed-9dfa-45e8f4fe2ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.MLP_text(input_size=200, dim_hidden1=128, dim_hidden2=86, dim_hidden3=30, dim_out=1).to(device)\n",
    "\n",
    "# data, target = next(iter(train_loader))\n",
    "\n",
    "# model(data).shape, data.shape, data[:3,:].shape\n",
    "# model(data), data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10bfc60f-17b3-49de-905e-3788d34ecefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # torch save model\n",
    "# torch.save(model.state_dict(), \"../models/model1\")\n",
    "\n",
    "# # upload mdoel as artifact\n",
    "# with mlflow.start_run(run_name=f\"Sentiment_Analysis_seltype_{args.seltype}_powd_{args.powd}_num_users_{args.ensize}_rounds_{args.rounds}\") as run:\n",
    "#     # mlflow.log_artifact(\"../models/model1\")\n",
    "#     params = {'Learning Rate': 0.005,\n",
    "#               'Batch Size': 32, \n",
    "#               'Total Client Number': 314, \n",
    "#               'Selected client number m': 8, \n",
    "#               'Local iteration number': 100, \n",
    "#               'Powd': 32,\n",
    "#               'Criterion': 'nn.BCELoss()',\n",
    "#               'Optimizer': 'torch.optim.SGD'\n",
    "#              }\n",
    "#     mlflow.log_params(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef75438-7d04-4e71-8f3a-2071fbfd9eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download model\n",
    "# runId = \"2bcbf82e541345cc9e56885cd0de030d\"\n",
    "# artifact_name = \"model1\"\n",
    "# mlflow.artifacts.download_artifacts(artifact_uri=f\"runs:/{runId}/{artifact_name}\", dst_path=\"../models\")\n",
    "# # torch load model\n",
    "# model = models.MLP_text(input_size=200, dim_hidden1=128, dim_hidden2=86, dim_hidden3=30, dim_out=1).to(device)\n",
    "# model.load_state_dict(torch.load(\"../models/model1\"))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54dd881-acd9-4959-85e4-2b79a7a49bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d813706-3504-4aee-a454-a2109c39c8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prediction = model(data)\n",
    "# signature = infer_signature(data, target)\n",
    "\n",
    "# model_info = mlflow.pyfunc.log_model(python_model=model(), \n",
    "#                                      artifact_path=\"my_model\", \n",
    "#                                      signature=data[:3,:].to_numpy()\n",
    "#                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32cddb-8824-4f4a-bf45-fb0a75047a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
